{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pdfminer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNza/IuLA8cKw8AhseDeU8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maviya5/Dissertation/blob/master/pdfminer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4VTm8cCC4I9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b75ffeef-262e-4dc1-8cfa-e92a663af88d"
      },
      "source": [
        "!pip install pdfminer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfminer\n",
            "  Using cached https://files.pythonhosted.org/packages/71/a3/155c5cde5f9c0b1069043b2946a93f54a41fd72cc19c6c100f6f2f5bdc15/pdfminer-20191125.tar.gz\n",
            "Collecting pycryptodome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/16/da16a22d47bac9bf9db39f3b9af74e8eeed8855c0df96be20b580ef92fff/pycryptodome-3.9.7-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 321kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pdfminer\n",
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfminer: filename=pdfminer-20191125-cp36-none-any.whl size=6140057 sha256=31bbd9b24e567fbf9f942b72a5b1c58d7b662114a3b246e9188c8268595df701\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/00/af/720a55d74ba3615bb4709a3ded6dd71dc5370a586a0ff6f326\n",
            "Successfully built pdfminer\n",
            "Installing collected packages: pycryptodome, pdfminer\n",
            "Successfully installed pdfminer-20191125 pycryptodome-3.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tGDMe9JDQw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pdf2txt.py -o output.txt trial.pdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va3_OHiLFOsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd57398a-3e45-4919-8ca5-bb69744b5a22"
      },
      "source": [
        "!cat output.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article\n",
            "\n",
            "On methods and tools of table\n",
            "detection, extraction and annotation in\n",
            "PDF documents\n",
            "\n",
            "Journal of Information Science\n",
            "2015, Vol. 41(1) 41–57\n",
            "Ó The Author(s) 2014\n",
            "Reprints and permissions:\n",
            "sagepub.co.uk/journalsPermissions.nav\n",
            "DOI: 10.1177/0165551514551903\n",
            "jis.sagepub.com\n",
            "\n",
            "Shah Khusro\n",
            "Department of Computer Science, University of Peshawar, Pakistan\n",
            "\n",
            "Asima Latif\n",
            "Department of Computer Science, University of Peshawar, Pakistan\n",
            "\n",
            "Irfan Ullah\n",
            "Department of Computer Science, University of Peshawar, Pakistan\n",
            "\n",
            "Abstract\n",
            "Table detection, extraction and annotation have been an important research problem for years. To handle this issue, different\n",
            "approaches have been designed for different types of documents. Among these PDF is a widely used format for preserving and pre-\n",
            "senting different types of documents. We investigate the state of the art in table detection, extraction and annotation in PDF docu-\n",
            "ments. Because of varying table structural anatomy, the state of the art in table-related research enumerates a number of approaches\n",
            "that are critically and analytically investigated for identifying their strengths and limitations as well as for making recommendations for\n",
            "further improvement. An evaluation framework is contributed that compares different information extraction tools that may be used\n",
            "in table detection, extraction and annotation. We found very limited attention towards these aspects in books, especially books in\n",
            "PDF format. There is no searching solution that can find books having tables that are semantically related to a table in a given book.\n",
            "\n",
            "Keywords\n",
            "Table detection; table extraction; table annotation; semantic table extraction\n",
            "\n",
            "1. Introduction\n",
            "\n",
            "In today’s digital world most information is unstructured, about 80% of it being textual and presented to users in a vari-\n",
            "ety of formats and structures [1]. PDF, which is short for Portable Document Format, is the most common among these.\n",
            "Being portable, PDF allows users to easily view documents and discuss their ideas with each other without taking care\n",
            "of the underlying platform. In PDF documents are presented in a way that is independent of the application software or\n",
            "hardware that was originally used for their production [2]. According to Merz, PDF preserves the structure and layout of\n",
            "a document both on screen as well as during printing. Merz views it as a file format that saves graphically and typogra-\n",
            "phically complex documents [3]. From a reader’s point of view its most exciting properties include platform indepen-\n",
            "dence, portability, compression and font independence (include font descriptor). Being descendent from PostScript (PS)\n",
            "Page Description Programming Language, it avoids programming for the sake of simplicity; however, it creates com-\n",
            "plexities in machine readability. This is because of its layout-oriented format that focuses on human readability, making\n",
            "its further processing difficult to handle. Therefore, the development of complex algorithms is required for text recogni-\n",
            "tion, editing and reinventing structural information. From a PDF developer’s point of view, the exciting characteristics\n",
            "include random access because of cross-referenced table and incremental updates [3].\n",
            "\n",
            "Corresponding author:\n",
            "Shah Khusro, Department of Computer Science, University of Peshawar, Peshawar, 25120, Pakistan.\n",
            "Email: khusro@upesh.edu.pk\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "42\n",
            "\n",
            "Several open-source and proprietary tools are available for information extraction form PDF documents; however,\n",
            "output is not always accurate. There are several elements of a PDF that may produce errors during the conversion process\n",
            "[4], like spaces between words, hyphens, emphasis, superscripting and subscripting, subfonting and special characters.\n",
            "Extracting structural information is also problematic in PDF documents. Examples include multiple columns, paragraph\n",
            "delineation, page headers and footers, tables, graphics and mathematical equations. Among these, tables are the hardest\n",
            "elements to extract. This review paper is a serious attempt towards the state of the art in table detection, extraction, explo-\n",
            "ration and semantic annotation along with different tools and techniques that have been developed and may be used so\n",
            "far for such purposes. The rest of the paper is organized as follows: Section 2 investigates different approaches towards\n",
            "defining tables and highlights the importance of table from different aspects; Section 3 presents an evaluation framework\n",
            "for comparing different open-source and proprietary tools that may be used for table detection, extraction and annotation;\n",
            "Section 4 presents the state of the art in table detection, extraction and annotations; and finally Section 5 concludes our\n",
            "discussion and describes some open issues and recommendations for future work.\n",
            "\n",
            "2. Tables and their importance\n",
            "\n",
            "Tables are important and valuable structures in both printed and digital media and play a vital role in augmenting under-\n",
            "standing of a particular topic, an issue of interest or phenomena. This section presents some definitions of tables that aim\n",
            "to explore their nature and investigates their importance from various aspects.\n",
            "\n",
            "2.1. Defining tables\n",
            "\n",
            "Various approaches exist towards table definition. A table is a representation of a set of relations between organized\n",
            "hierarchical concepts or categories [5]. It is a superstructure in plain text that is imposed on a character-level grid [6]. It\n",
            "comprises a regular and repetitive structure along one dimension in order for data type to be determined using either a\n",
            "horizontal or vertical index [7]. It is an object that uses linear visual clues for simultaneous description of logical con-\n",
            "nections between well-defined and discrete content entries in it where a content entry is the basic entity of information\n",
            "that can be any visual symbol [8]. All of these definitions sound reasonable for describing tables; however, the most ver-\n",
            "ifiable and reliable definition comes from Cameron Silva, in which a table is a graphical grid of a matrix Mi,j, (a) with\n",
            "atomic elements i, j, (b) having linear visual clues such as elements in each row i tend to align horizontally where ele-\n",
            "ments of a column j tend to align vertically and (c) with linear visual clues that depict some logical relationships [9].\n",
            "The question what constitutes a table is indeed still difficult to answer [10].\n",
            "\n",
            "Tables differ significantly in variety, structure, flexibility, notation, representation and use [9]. Normally a table has\n",
            "two forms: raw text tables, generally ASCII text in monospace font, delimited by white space and/or special characters,\n",
            "and rich text tables like those formatted using LaTeX, PDF, HTML and other such formats [11]. Because of these differ-\n",
            "ent representations, no single table processing algorithm works for all mediums. Each algorithm has limitations, and no\n",
            "single algorithm can provide ideal performance considering all evaluation metrics [12].\n",
            "\n",
            "Usually tables are perceived as rectangular structures having rows and columns made up of cells. Inside a table, col-\n",
            "umn and row boundaries are normally recognized as delimiters that are very important for table detection. These delimi-\n",
            "ters are diverse in shape and structure. For example row delimiters may be sequences of punctuation characters, blank\n",
            "lines, new line characters or a mixture of these. Column delimiters may be repeated with white spaces and vertical bar\n",
            "characters. A cell may contain nested tables, other shapes and so on. Simply, a table has diverse structure that depends\n",
            "upon the media hosting it, the need for its creation and the content it contains. The diverse nature, structural irregularities\n",
            "and sometimes missing data make table processing a challenging task [13].\n",
            "\n",
            "2.2. Importance of tables in documents\n",
            "\n",
            "A table is a compact and efficient presentation that is commonly used in various types of documents, especially for\n",
            "describing statistical and relational information [14]. It enables readers to rapidly search, compare and understand facts\n",
            "and draw conclusions [15]. It is viewed as a two-dimensional representation of logical relationships between groups of\n",
            "data [16] where the header row represents the type of data that will be stored in subsequent rows of the table, forming\n",
            "instances of the entity being represented by the table. Thus values stored in a particular row represent some relationship\n",
            "with each other that gives a clue that a huge amount of information can be extracted from table structure. This is an\n",
            "important issue in the field of document layout analysis [13]. Similarly, for many other applications, it is important to\n",
            "understand the structure and content-sharing characteristics of tables. For example, in most research and discovery fields,\n",
            "experimental as well as other factual data are represented as well as explained with the help of tables [17].\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "2.3. Tables as a summarized view\n",
            "\n",
            "43\n",
            "\n",
            "Tables present valuable information in a summarized and illustrated manner surrounded by words, symbols and other\n",
            "informative material inside text and thus need to be automatically detected for their searching and retrieval [18]. While\n",
            "surfing web pages or studying scholarly documents, including books, tables are equally distributed everywhere, helping\n",
            "users and augmenting understanding on a particular issue, topic or phenomena. In particular, books emphasize the impor-\n",
            "tance of using tables. Normally every book contains at least a table of contents that helps users in obtaining a bird’s-eye\n",
            "view of the content presented in the book and helps them decide whether to choose the book for reading or leave it and\n",
            "search for another books. Tables also save users from digging into large text for finding relevant information. Although\n",
            "the main concern of this review article is on extraction and annotation of tables in PDF documents, this investigation\n",
            "was performed in the context of a research project aimed at ‘semantically’ searching inside books. As books are primar-\n",
            "ily available in PDF format, the paper focuses on table extraction and annotation from books available in PDF format.\n",
            "Books in digitized form are also made available in PDF form by digitization projects like Google Books, which are made\n",
            "searchable after applying OCR/ICR techniques. Similarly, scanned versions of printed books and books in other formats\n",
            "such as e-pub, kindle, DjVu, chm and other mobile formats are worth investigation. However, PDF, being the primary\n",
            "presentation and preservation format, is the main focus of our attention. In the context of our project and as a standard\n",
            "international practice, books in other formats are converted to/from PDF at the time of import/export.\n",
            "\n",
            "2.4. Importance of tables in information retrieval\n",
            "\n",
            "With the growth of the World Wide Web and the speedy expansion of digital libraries, tables are becoming one of most\n",
            "valuable information sources that need be indexed and searched. However, the available searching solutions, including\n",
            "web search engines, book search engines and digital libraries, do not provide adequate, precise and accurate table search-\n",
            "ing and ranking. This is because these information retrieval schemes are inadequate for table searching and extraction.\n",
            "Table search is highly dependent on precise table extraction. As there is no standard markup language, everyone is gen-\n",
            "erating tables using their own styles and requirements. Thus a universal metadata specification for tables has not yet been\n",
            "developed [17]. We are also interested in finding or developing searching solutions that can find tables in relation to a\n",
            "particular table in a given book and tell us how much summarized or detailed information these other tables provide\n",
            "either in support or in contrast to the table at hand. This is possible if we carefully incorporate semantics into the table\n",
            "extraction, annotation, and search process. With the incorporation of such semantics, understanding of a particular table\n",
            "will become much easier and readers will not have to manually search for books, which will reduce the resulting cogni-\n",
            "tive load. In the next section we present an evaluation framework for comparing information extraction (IE) tools and\n",
            "techniques for extracting tables or other information and depict their features in the form of tables.\n",
            "\n",
            "3. Comparing IE tools for extracting tables and other information from PDF documents\n",
            "\n",
            "Table 1 enumerates basic features and properties of IE tools and techniques used for PDF documents by introducing an\n",
            "evaluation framework that compares these tools and techniques from the perspective of table detection, extraction and\n",
            "annotation. The purpose of this section is to analyse how the tools in Table 1 support our desired features for data\n",
            "extraction.\n",
            "\n",
            "As far as table extraction is concerned, there are some tools that can extract PDF text and layout information, but are\n",
            "not able to extract tables directly form PDF documents; however, their output can be utilized using some heuristics for\n",
            "extracting tables, like pdf2table and greenstone, which are based on the output of pdf2html suite. Similarly output gener-\n",
            "ated by iText, pdfBox and ICEPdf can be used programmatically for table identification and extraction purposes. There\n",
            "are libraries that support PDF and table extraction. For example, JPedal provides built-in classes for table extraction but\n",
            "results are not always satisfactory. Most of the tools in Table 1 are commercial PDF browsers. Table identification/\n",
            "extraction is one of the many features that these tool may provide or may be used for such purposes. These browsers are\n",
            "based on the selection of tables in PDF documents and export them in other formats like ABBYY PDF Transformer 3.0,\n",
            "Okular PDF reader ABBYY FineReader 11.0 Corporate Edition, Adobe Acrobat XI Pro, OmniPage 18 Professional and\n",
            "Nitro Pro 8. Tools that are purely dedicated only to tables include Tabula, TableSeer, pdf-table-extract and pdf2table.\n",
            "Among these tools TableSeer can retrieve, search and rank tables. Tabula and pdf-table-extract can extract tables from\n",
            "PDF documents. Pdf2table not only extracts tables from PDF documents but also presents a graphical user interface that\n",
            "supports users in manually editing parts of the extracted output. The tool is limited in showing good performance for\n",
            "small PDF documents only and works poorly with large documents such as e-books. Because of the diverse nature of\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "y\n",
            "r\n",
            "a\n",
            "r\n",
            "b\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "l\n",
            "a\n",
            "t\n",
            "i\n",
            "g\n",
            "i\n",
            "d\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "t\n",
            "i\n",
            "u\n",
            "s\n",
            "\n",
            "l\n",
            "\n",
            "m\n",
            "t\n",
            "h\n",
            "2\n",
            "d\n",
            "p\n",
            "\n",
            "f\n",
            "\n",
            "n\n",
            "o\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "B\n",
            "\n",
            "t\n",
            "u\n",
            "o\n",
            "y\n",
            "a\n",
            "l\n",
            "\n",
            "l\n",
            "l\n",
            "a\n",
            "\n",
            "e\n",
            "r\n",
            "o\n",
            "t\n",
            "S\n",
            "\n",
            "s\n",
            "e\n",
            "i\n",
            "t\n",
            "i\n",
            "l\n",
            "i\n",
            "t\n",
            "u\n",
            "\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "e\n",
            "r\n",
            "c\n",
            "\n",
            "r\n",
            "u\n",
            "o\n",
            "o\n",
            "c\n",
            "\n",
            "l\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "p\n",
            "y\n",
            "r\n",
            "c\n",
            "n\n",
            "e\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "r\n",
            "u\n",
            "t\n",
            "a\n",
            "n\n",
            "g\n",
            "i\n",
            "s\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "b\n",
            "-\n",
            "I\n",
            "\n",
            "K\n",
            "P\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "r\n",
            "g\n",
            "e\n",
            "t\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "s\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "c\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "p\n",
            "p\n",
            "a\n",
            "\n",
            "t\n",
            "n\n",
            "e\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "c\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "X\n",
            "/\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "r\n",
            "r\n",
            "o\n",
            "c\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "o\n",
            "n\n",
            "n\n",
            "a\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "c\n",
            "i\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "c\n",
            "\n",
            "i\n",
            "\n",
            "/\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "a\n",
            "v\n",
            "e\n",
            "i\n",
            "r\n",
            "t\n",
            "e\n",
            "r\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            ",\n",
            "s\n",
            "h\n",
            "p\n",
            "a\n",
            "r\n",
            "g\n",
            "a\n",
            "r\n",
            "a\n",
            "p\n",
            "\n",
            "e\n",
            "v\n",
            "r\n",
            "e\n",
            "s\n",
            "e\n",
            "r\n",
            "P\n",
            "\n",
            "—\n",
            "\n",
            ".\n",
            "t\n",
            "x\n",
            "e\n",
            "t\n",
            "\n",
            "l\n",
            "\n",
            "n\n",
            "m\n",
            "u\n",
            "o\n",
            "c\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "m\n",
            "t\n",
            "h\n",
            "2\n",
            "d\n",
            "p\n",
            "\n",
            "f\n",
            "\n",
            "n\n",
            "o\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "B\n",
            "\n",
            "/\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "/\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "m\n",
            "t\n",
            "h\n",
            "\n",
            "o\n",
            "t\n",
            "\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "o\n",
            "o\n",
            "t\n",
            "\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "m\n",
            "m\n",
            "o\n",
            "c\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "o\n",
            "t\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "w\n",
            "e\n",
            "v\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "i\n",
            "r\n",
            "p\n",
            "\n",
            ",\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "i\n",
            "d\n",
            "E\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "V,\n",
            "S\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "F\n",
            "T\n",
            "R\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            ".\n",
            "\n",
            "d\n",
            "r\n",
            "o\n",
            "W\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "F\n",
            "T\n",
            "R\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "s\n",
            "e\n",
            "r\n",
            "u\n",
            "t\n",
            "a\n",
            "e\n",
            "F\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "e\n",
            "d\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "e\n",
            "c\n",
            "r\n",
            "u\n",
            "o\n",
            "S\n",
            "\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "u\n",
            "p\n",
            "t\n",
            "u\n",
            "O\n",
            "\n",
            "/\n",
            "t\n",
            "x\n",
            "e\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "/\n",
            "t\n",
            "n\n",
            "o\n",
            "f\n",
            "/\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "a\n",
            "t\n",
            "a\n",
            "d\n",
            "a\n",
            "t\n",
            "e\n",
            "m\n",
            "\n",
            "m\n",
            "r\n",
            "o\n",
            "f\n",
            "t\n",
            "a\n",
            "l\n",
            "P\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "L\n",
            "\n",
            "s\n",
            "l\n",
            "o\n",
            "o\n",
            "T\n",
            "\n",
            "T\n",
            "\n",
            "T\n",
            "\n",
            "I\n",
            "/\n",
            "\n",
            "T\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "I\n",
            "/\n",
            "\n",
            "T\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "/\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "x\n",
            "u\n",
            "n\n",
            "L\n",
            "\n",
            "i\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "l\n",
            "r\n",
            "e\n",
            "P\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "n\n",
            "o\n",
            "h\n",
            "t\n",
            "y\n",
            "p\n",
            "\n",
            "+\n",
            "a\n",
            "+\n",
            "v\n",
            "C\n",
            "a\n",
            "J\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "]\n",
            "0\n",
            "2\n",
            "1\n",
            "[\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "X\n",
            "e\n",
            "r\n",
            "o\n",
            "P\n",
            "c\n",
            "S\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "1\n",
            "e\n",
            "n\n",
            "o\n",
            "t\n",
            "s\n",
            "n\n",
            "e\n",
            "e\n",
            "r\n",
            "G\n",
            "\n",
            "5\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "-\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "-\n",
            "f\n",
            "d\n",
            "p\n",
            "\n",
            "l\n",
            "\n",
            "2\n",
            "x\n",
            "o\n",
            "B\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "3\n",
            "\n",
            "t\n",
            "x\n",
            "e\n",
            "T\n",
            "\n",
            "i\n",
            "\n",
            "f\n",
            "\n",
            "4\n",
            "d\n",
            "P\n",
            "E\n",
            "C\n",
            "\n",
            "I\n",
            "\n",
            "7\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "2\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "6\n",
            "a\n",
            "l\n",
            "u\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "y\n",
            "r\n",
            "e\n",
            "V\n",
            "\n",
            "8\n",
            "r\n",
            "o\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "9\n",
            "o\n",
            "o\n",
            "T\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "n\n",
            "O\n",
            "e\n",
            "b\n",
            "o\n",
            "d\n",
            "A\n",
            "\n",
            "l\n",
            "\n",
            "0\n",
            "1\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "2\n",
            "d\n",
            "P\n",
            "\n",
            "f\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "/\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "l\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "l\n",
            "a\n",
            "d\n",
            "e\n",
            "P\n",
            "\n",
            "J\n",
            "\n",
            ".\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "o\n",
            "n\n",
            "n\n",
            "a\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "e\n",
            "d\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "u\n",
            "\n",
            "e\n",
            "b\n",
            "\n",
            "y\n",
            "a\n",
            "m\n",
            "\n",
            "t\n",
            "a\n",
            "h\n",
            "t\n",
            "\n",
            "s\n",
            "l\n",
            "o\n",
            "o\n",
            "t\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "n\n",
            "\n",
            "f\n",
            "\n",
            "i\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "r\n",
            "a\n",
            "p\n",
            "m\n",
            "o\n",
            "c\n",
            "\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "k\n",
            "r\n",
            "o\n",
            "w\n",
            "e\n",
            "m\n",
            "a\n",
            "r\n",
            "f\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "u\n",
            "l\n",
            "a\n",
            "v\n",
            "E\n",
            "\n",
            ".\n",
            "\n",
            "l\n",
            "\n",
            "1\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "p\n",
            "u\n",
            "s\n",
            "\n",
            ",\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            ",\n",
            "s\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "e\n",
            "r\n",
            "u\n",
            "c\n",
            "e\n",
            "s\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "r\n",
            "i\n",
            "a\n",
            "p\n",
            "e\n",
            "R\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "e\n",
            "d\n",
            "o\n",
            "c\n",
            "n\n",
            "U\n",
            "\n",
            "i\n",
            "\n",
            "M\n",
            "\n",
            "/\n",
            "I\n",
            "/\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "l\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "44\n",
            "\n",
            ")\n",
            "d\n",
            "e\n",
            "u\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "o\n",
            "c\n",
            "(\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "l\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "p\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "m\n",
            "\n",
            "r\n",
            "e\n",
            "h\n",
            "t\n",
            "o\n",
            "\n",
            "h\n",
            "t\n",
            "i\n",
            "\n",
            "w\n",
            "s\n",
            "k\n",
            "r\n",
            "o\n",
            "w\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "n\n",
            "i\n",
            "g\n",
            "n\n",
            "e\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "/\n",
            "e\n",
            "v\n",
            "e\n",
            "i\n",
            "r\n",
            "t\n",
            "e\n",
            "r\n",
            "/\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "t\n",
            "u\n",
            "o\n",
            "y\n",
            "a\n",
            "l\n",
            "\n",
            "l\n",
            "a\n",
            "n\n",
            "i\n",
            "g\n",
            "i\n",
            "r\n",
            "o\n",
            "\n",
            "e\n",
            "h\n",
            "t\n",
            "\n",
            "h\n",
            "t\n",
            "i\n",
            "\n",
            "w\n",
            "s\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "d\n",
            "e\n",
            "n\n",
            "i\n",
            "a\n",
            "t\n",
            "e\n",
            "r\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "o\n",
            "o\n",
            "t\n",
            "\n",
            "s\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "k\n",
            "n\n",
            "a\n",
            "r\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "T\n",
            "\n",
            "—\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "—\n",
            "\n",
            "4\n",
            "1\n",
            "0\n",
            "3\n",
            "\n",
            ".\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "Y\n",
            "Y\n",
            "B\n",
            "B\n",
            "A\n",
            "\n",
            "r\n",
            "e\n",
            "m\n",
            "r\n",
            "o\n",
            "f\n",
            "s\n",
            "n\n",
            "a\n",
            "r\n",
            "T\n",
            "\n",
            "]\n",
            "1\n",
            "2\n",
            "[\n",
            "\n",
            "r\n",
            "e\n",
            "e\n",
            "S\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "p\n",
            "y\n",
            "r\n",
            "c\n",
            "n\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "r\n",
            "e\n",
            "v\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "v\n",
            "e\n",
            "\n",
            "l\n",
            "\n",
            "y\n",
            "t\n",
            "i\n",
            "r\n",
            "u\n",
            "c\n",
            "e\n",
            "s\n",
            "\n",
            "t\n",
            "s\n",
            "u\n",
            "d\n",
            "A\n",
            "\n",
            "j\n",
            "\n",
            "s\n",
            "k\n",
            "r\n",
            "a\n",
            "m\n",
            "k\n",
            "o\n",
            "o\n",
            "b\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "k\n",
            "c\n",
            "e\n",
            "h\n",
            "c\n",
            "\n",
            "y\n",
            "c\n",
            "n\n",
            "e\n",
            "t\n",
            "s\n",
            "i\n",
            "s\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "p\n",
            "y\n",
            "r\n",
            "c\n",
            "n\n",
            "e\n",
            "\n",
            ",\n",
            "s\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "s\n",
            "i\n",
            "m\n",
            "r\n",
            "e\n",
            "p\n",
            "\n",
            ",\n",
            "s\n",
            "d\n",
            "r\n",
            "o\n",
            "w\n",
            "s\n",
            "s\n",
            "a\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "/\n",
            "c\n",
            "o\n",
            "d\n",
            "/\n",
            "t\n",
            "x\n",
            "e\n",
            "T\n",
            "\n",
            "e\n",
            "d\n",
            "o\n",
            "c\n",
            "n\n",
            "U\n",
            "\n",
            "i\n",
            "\n",
            "M\n",
            "\n",
            "/\n",
            "I\n",
            "/\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            ",\n",
            "\n",
            "S\n",
            "P\n",
            "X\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "F,\n",
            "T\n",
            "R\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "T\n",
            "\n",
            "-\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "x\n",
            "u\n",
            "n\n",
            "L\n",
            "\n",
            "i\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "+\n",
            "+\n",
            "C\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "t\n",
            "e\n",
            "N\n",
            "\n",
            ".\n",
            "\n",
            ",\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "1\n",
            "1\n",
            "r\n",
            "e\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            "d\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "o\n",
            "S\n",
            "\n",
            "y\n",
            "b\n",
            "\n",
            "r\n",
            "e\n",
            "z\n",
            "y\n",
            "l\n",
            "a\n",
            "n\n",
            "A\n",
            "-\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "y\n",
            "b\n",
            "\n",
            "r\n",
            "e\n",
            "z\n",
            "y\n",
            "l\n",
            "a\n",
            "n\n",
            "A\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "]\n",
            "9\n",
            "1\n",
            "[\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "k\n",
            "e\n",
            "o\n",
            "m\n",
            "h\n",
            "c\n",
            "S\n",
            "\n",
            "i\n",
            "\n",
            "n\n",
            "u\n",
            "y\n",
            "m\n",
            "A\n",
            "\n",
            "]\n",
            "0\n",
            "2\n",
            "[\n",
            "s\n",
            "e\n",
            "i\n",
            "g\n",
            "o\n",
            "o\n",
            "n\n",
            "h\n",
            "c\n",
            "e\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            "3\n",
            "1\n",
            "T\n",
            "E\n",
            "T\n",
            "b\n",
            "L\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "s\n",
            "t\n",
            "h\n",
            "g\n",
            "i\n",
            "e\n",
            "H\n",
            "-\n",
            "3\n",
            "\n",
            "2\n",
            "1\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "45\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "\n",
            "l\n",
            "l\n",
            "\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "w\n",
            "e\n",
            "v\n",
            "\n",
            "i\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "v\n",
            "o\n",
            "m\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "p\n",
            "u\n",
            "s\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "i\n",
            "r\n",
            "p\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            ",\n",
            "s\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "e\n",
            "t\n",
            "o\n",
            "u\n",
            "q\n",
            "\n",
            "y\n",
            "\n",
            "l\n",
            "i\n",
            "s\n",
            "a\n",
            "e\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            "s\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "e\n",
            "v\n",
            "o\n",
            "r\n",
            "p\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "o\n",
            "n\n",
            "n\n",
            "a\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "s\n",
            "s\n",
            "e\n",
            "c\n",
            "o\n",
            "r\n",
            "p\n",
            "\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "m\n",
            "a\n",
            "e\n",
            "r\n",
            "t\n",
            "s\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "—\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "o\n",
            "n\n",
            "n\n",
            "a\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "c\n",
            "i\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "c\n",
            "\n",
            "i\n",
            "\n",
            "/\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "a\n",
            "v\n",
            "e\n",
            "i\n",
            "r\n",
            "t\n",
            "e\n",
            "r\n",
            "\n",
            "s\n",
            "e\n",
            "r\n",
            "u\n",
            "t\n",
            "a\n",
            "e\n",
            "F\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "e\n",
            "d\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "e\n",
            "c\n",
            "r\n",
            "u\n",
            "o\n",
            "S\n",
            "\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "u\n",
            "p\n",
            "t\n",
            "u\n",
            "O\n",
            "\n",
            "/\n",
            "t\n",
            "x\n",
            "e\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "/\n",
            "t\n",
            "n\n",
            "o\n",
            "f\n",
            "/\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "a\n",
            "t\n",
            "a\n",
            "d\n",
            "a\n",
            "t\n",
            "e\n",
            "m\n",
            "\n",
            "m\n",
            "r\n",
            "o\n",
            "f\n",
            "t\n",
            "a\n",
            "l\n",
            "P\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "L\n",
            "\n",
            "s\n",
            "l\n",
            "o\n",
            "o\n",
            "T\n",
            "\n",
            ")\n",
            "d\n",
            "e\n",
            "u\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "o\n",
            "c\n",
            "(\n",
            "\n",
            ".\n",
            "\n",
            "1\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "o\n",
            "r\n",
            "p\n",
            "\n",
            ",\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "e\n",
            "r\n",
            "c\n",
            "\n",
            ",\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "s\n",
            "u\n",
            "\n",
            "o\n",
            "t\n",
            "\n",
            "s\n",
            "e\n",
            "\n",
            "l\n",
            "i\n",
            "f\n",
            "\n",
            "y\n",
            "s\n",
            "a\n",
            "E\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "F,\n",
            "T\n",
            "R\n",
            "\n",
            ",\n",
            "\n",
            "c\n",
            "o\n",
            "D\n",
            "\n",
            "I\n",
            "/\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "d\n",
            "u\n",
            "o\n",
            "c\n",
            "\n",
            "l\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "r\n",
            "o\n",
            "b\n",
            "a\n",
            "l\n",
            "l\n",
            "\n",
            "o\n",
            "c\n",
            "\n",
            ",\n",
            "s\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "e\n",
            "r\n",
            "u\n",
            "c\n",
            "e\n",
            "s\n",
            "\n",
            "y\n",
            "t\n",
            "i\n",
            "v\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "n\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            ",\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "p\n",
            "u\n",
            "s\n",
            "A\n",
            "/\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "c\n",
            "a\n",
            "f\n",
            "r\n",
            "e\n",
            "t\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "x\n",
            "e\n",
            "p\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "-\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            ",\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            ",\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "e\n",
            "r\n",
            "c\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "c\n",
            "a\n",
            "f\n",
            "r\n",
            "e\n",
            "t\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "p\n",
            "m\n",
            "S\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "c\n",
            "o\n",
            "d\n",
            "/\n",
            "l\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "F\n",
            "/\n",
            "I\n",
            "/\n",
            "\n",
            "T\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            ",\n",
            "\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "F,\n",
            "T\n",
            "R\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "/\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "c\n",
            "a\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "5\n",
            "1\n",
            "r\n",
            "e\n",
            "d\n",
            "a\n",
            "e\n",
            "r\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "r\n",
            "a\n",
            "l\n",
            "u\n",
            "k\n",
            "O\n",
            "\n",
            "r\n",
            "e\n",
            "d\n",
            "a\n",
            "e\n",
            "R\n",
            "e\n",
            "n\n",
            "F\n",
            "Y\n",
            "Y\n",
            "B\n",
            "B\n",
            "A\n",
            "\n",
            "i\n",
            "\n",
            "I\n",
            "\n",
            "X\n",
            "\n",
            "t\n",
            "a\n",
            "b\n",
            "o\n",
            "r\n",
            "c\n",
            "A\n",
            "e\n",
            "b\n",
            "o\n",
            "d\n",
            "A\n",
            "\n",
            "7\n",
            "1\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "r\n",
            "o\n",
            "p\n",
            "r\n",
            "o\n",
            "C\n",
            "0\n",
            "1\n",
            "1\n",
            "\n",
            ".\n",
            "\n",
            "6\n",
            "1\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "i\n",
            "d\n",
            "E\n",
            "\n",
            "8\n",
            "1\n",
            "\n",
            "i\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "P\n",
            "n\n",
            "m\n",
            "O\n",
            "\n",
            "l\n",
            "a\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "s\n",
            "e\n",
            "f\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "8\n",
            "1\n",
            "\n",
            "9\n",
            "1\n",
            "8\n",
            "\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "o\n",
            "r\n",
            "t\n",
            "i\n",
            "\n",
            "N\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "46\n",
            "\n",
            "tables, no tool is perfect in extracting all sorts of tables. TableSeer is the only available tool that not only identifies tables\n",
            "but also provides table search and ranking facilities; however, its performance is compromised for complex tables.\n",
            "\n",
            "After reviewing all PDF table-related tools, we find not even a single open-source or proprietary tool that can extract\n",
            "and annotate PDF tables. Therefore, the intense need today is for a PDF table extraction and annotation tool that can\n",
            "extract tables from PDF document with good accuracy and annotate them using surrounding text or using external\n",
            "sources.\n",
            "\n",
            "4. State of the art in table detection, extraction and annotation\n",
            "\n",
            "A detailed bibliography on table segmentation and extraction can be found on visionbib website.20 Much research and\n",
            "development has been carried out on extracting tables from documents and web pages [5, 22], but owing to diversity in\n",
            "table layouts, no work is perfect in extracting all types of tables. Some commonly used words in table processing are\n",
            "detection, extraction [9, 23], interpretation [9] and understanding [24]. Similarly relatively little work has been done\n",
            "focusing semantics extraction from tables and almost no work has been done on extracting, interpreting and semantically\n",
            "annotating book tables for finding/ranking related tables in other books. Only Fang et al. [25] evaluate their table extrac-\n",
            "tion algorithm on an e-book dataset and a scientific document dataset. Their algorithm is integrated into a commercial\n",
            "software package for large-scale Chinese e-book production. Quite simplistic and out-dated surveys about table detection\n",
            "approaches have been contributed by Zanibbi et al. [26] and Silva et al. [9]. This work, however, investigates the state of\n",
            "the art in this area and identifies the underlying problems in these different techniques. The paper investigates research\n",
            "efforts as well as some unsolved key issues. We have also contributed an evaluation framework for comparing PDF\n",
            "extraction tools and assessed their quality for table extraction and annotation. The paper makes some useful recommen-\n",
            "dations about techniques and their usability in the case of tables.\n",
            "\n",
            "The research on tables can be divided into two categories, namely Table Extraction and Table Annotation. The pur-\n",
            "\n",
            "pose of this section is to present the state of the art in table detection, extraction and retrieval.\n",
            "\n",
            "4.1. Table detection in PDF documents\n",
            "\n",
            "PDF is a higher-level document representation format [25] where detecting tables from such documents remains disre-\n",
            "garded by researchers. Therefore, very little work has been carried out on such formats [21, 48, 58, 60]. The most valu-\n",
            "able work regarding table detection from PDF document is TableSeer, which utilizes PDF2TET, PDFBox and Text\n",
            "Extraction Toolkit (TET). The initial step before table extraction from any document is table recognition. In table recog-\n",
            "nition Zanibbi uses table location and composition (a table model) for recovering tables from encoded documents. In this\n",
            "approach, table anatomy consists of column, row, cell, block, headers, body and associated text regions [26].\n",
            "\n",
            "4.1.1. Table detection methodologies. There are three major categories of table detection methodologies: predefined layout\n",
            "approaches [37], heuristics-based approaches [31, 32, 54, 89] and statistical approaches, as well as a mixture of both\n",
            "heuristic and statistical approaches [14]. Shamilian presents a predefine layout based table identification and segmenta-\n",
            "tion algorithm [37]. Their contribution is the provision of graphical user interface for defining new layouts. The problem\n",
            "with their approach is the automatic control of the incoming document format. Also the approach works well only with\n",
            "single-column documents. Another predefined layout based approach is Mohemad et al. [50], which presents a typical\n",
            "work based on a predefined table layout structure for text, then associates text using a combination of heuristics-based,\n",
            "rule-based and predefined layout approaches. This approach shows good performance for tender documents, but being\n",
            "layout dependent, it cannot show good performance in general. Heuristics-based techniques remain dominant in litera-\n",
            "ture, as shown in Table 2. Kieninger [32] relies on complex heuristics that are based on local analysis for table segmen-\n",
            "tation. Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42,\n",
            "48, 52–61]. Interested readers may consult them for further details. Few research works pay attention to the use of statis-\n",
            "tical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61,\n",
            "66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65],\n",
            "the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70].\n",
            "Mostly these have been applied as off-the-shelf techniques with no investigation as to how they can be optimized for\n",
            "document analysis problems. Oro and Ruffolo [60] use a mixture of both heuristics and statistics. Wang and Hu [45] use\n",
            "both Decision Tree Classifier and SVM for finding fake and genuine entities. For this they utilize table layout and con-\n",
            "tent type and word groups as a base. Conditional Random Fields have been introduced by Lafferty et al. [65] for\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "47\n",
            "\n",
            "]\n",
            "7\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "6\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "6\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "8\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "8\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "4\n",
            "6\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "3\n",
            "6\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "\n",
            "]\n",
            "4\n",
            "1\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "3\n",
            "3\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "4\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "4\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "4\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "–\n",
            "3\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "8\n",
            "8\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "8\n",
            "[\n",
            "\n",
            "]\n",
            "4\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "6\n",
            "8\n",
            "–\n",
            "5\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "S\n",
            "L\n",
            "X\n",
            "\n",
            "I\n",
            "I\n",
            "\n",
            "C\n",
            "S\n",
            "A\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "]\n",
            "0\n",
            "5\n",
            "–\n",
            "8\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "4\n",
            "\n",
            "]\n",
            "2\n",
            "4\n",
            "\n",
            "]\n",
            "1\n",
            "6\n",
            "–\n",
            "6\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "4\n",
            "\n",
            "]\n",
            "2\n",
            "5\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "4\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "2\n",
            "[\n",
            "\n",
            "]\n",
            "1\n",
            "5\n",
            "[\n",
            "\n",
            "]\n",
            "0\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "1\n",
            "6\n",
            "–\n",
            "9\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "9\n",
            "[\n",
            "\n",
            "]\n",
            "9\n",
            "5\n",
            "\n",
            "]\n",
            "9\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "5\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "1\n",
            "6\n",
            "\n",
            "]\n",
            "4\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "3\n",
            "7\n",
            "–\n",
            "1\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "–\n",
            "5\n",
            "3\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "6\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "3\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "3\n",
            "[\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "I\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "5\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "6\n",
            "3\n",
            "[\n",
            "\n",
            "]\n",
            "3\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "3\n",
            "\n",
            "]\n",
            "7\n",
            "6\n",
            "–\n",
            "5\n",
            "6\n",
            "\n",
            "g\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "l\n",
            "\n",
            "e\n",
            "d\n",
            "o\n",
            "M\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "l\n",
            "i\n",
            "\n",
            "b\n",
            "a\n",
            "b\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "]\n",
            "7\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "[\n",
            "\n",
            "m\n",
            "o\n",
            "d\n",
            "n\n",
            "a\n",
            "R\n",
            "\n",
            "l\n",
            "a\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "i\n",
            "d\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "d\n",
            "e\n",
            "i\n",
            "f\n",
            "\n",
            "]\n",
            "4\n",
            "3\n",
            "–\n",
            "7\n",
            "2\n",
            "\n",
            "]\n",
            "3\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "9\n",
            "2\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "2\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "3\n",
            "\n",
            "t\n",
            "x\n",
            "e\n",
            "T\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "3\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "2\n",
            "[\n",
            "\n",
            "]\n",
            "5\n",
            "6\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "S\n",
            "\n",
            "M\n",
            "V\n",
            "S\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "b\n",
            "\n",
            "r\n",
            "e\n",
            "p\n",
            "p\n",
            "a\n",
            "r\n",
            "\n",
            "W\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "b\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "u\n",
            "R\n",
            "\n",
            "t\n",
            "u\n",
            "o\n",
            "y\n",
            "a\n",
            "l\n",
            "\n",
            "d\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "f\n",
            "e\n",
            "d\n",
            "e\n",
            "r\n",
            "P\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "b\n",
            "\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "r\n",
            "u\n",
            "e\n",
            "H\n",
            "\n",
            "l\n",
            "a\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "S\n",
            "\n",
            "s\n",
            "e\n",
            "h\n",
            "c\n",
            "a\n",
            "o\n",
            "r\n",
            "p\n",
            "p\n",
            "A\n",
            "\n",
            "—\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "g\n",
            "e\n",
            "S\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "g\n",
            "e\n",
            "S\n",
            "\n",
            "e\n",
            "p\n",
            "y\n",
            "t\n",
            "\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "D\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "c\n",
            "o\n",
            "L\n",
            "\n",
            ".\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "e\n",
            "r\n",
            "\n",
            "d\n",
            "e\n",
            "t\n",
            "a\n",
            "l\n",
            "e\n",
            "r\n",
            "-\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            ".\n",
            "\n",
            "l\n",
            "\n",
            "2\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "]\n",
            "0\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "9\n",
            "6\n",
            "\n",
            "]\n",
            "8\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "[\n",
            "\n",
            "r\n",
            "e\n",
            "i\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "C\n",
            "s\n",
            "e\n",
            "y\n",
            "a\n",
            "B\n",
            "\n",
            "e\n",
            "v\n",
            "i\n",
            "a\n",
            "N\n",
            "\n",
            "s\n",
            "e\n",
            "e\n",
            "r\n",
            "t\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "i\n",
            "c\n",
            "e\n",
            "D\n",
            "\n",
            "]\n",
            "4\n",
            "3\n",
            "[\n",
            "\n",
            "y\n",
            "p\n",
            "o\n",
            "r\n",
            "t\n",
            "n\n",
            "E\n",
            "m\n",
            "u\n",
            "m\n",
            "x\n",
            "a\n",
            "M\n",
            "\n",
            "i\n",
            "\n",
            "]\n",
            "4\n",
            "3\n",
            "[\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "d\n",
            "o\n",
            "m\n",
            "v\n",
            "o\n",
            "k\n",
            "r\n",
            "a\n",
            "M\n",
            "n\n",
            "e\n",
            "d\n",
            "d\n",
            "H\n",
            "\n",
            "i\n",
            "\n",
            "r\n",
            "e\n",
            "i\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "c\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            "c\n",
            "i\n",
            "t\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "S\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "48\n",
            "\n",
            "segment and label sequence data. Conditional Random Fields are used for part-of-speech tagging [65], shallow parsing\n",
            "[90] and named entity recognition [91] as well as for table detection [34].\n",
            "\n",
            "4.1.2. Tactics used in table detection. Different tactics are used for table detection, namely segmentation-based, rule-based\n",
            "and wrapper-based approaches. The segmentation-based approach is the assignment of physical description to the table\n",
            "by finding its cells, rows, columns and their positions [9]. PDF-TREX is based on segments in lines such as text lines,\n",
            "table lines and unknown lines. This technique works with single-column documents only. Considering white space dis-\n",
            "tributions inside text elements, it calculates horizontal and vertical threshold values based on smallest distance measure\n",
            "between text elements and the last cluster of identical text elements [60]. The contribution of technique is the identifica-\n",
            "tion of spanning columns and empty cells as well as the publication of a freely available dataset. Limitations of this tech-\n",
            "nique include the use of a predefined threshold for calculating distance between text elements as this can produce wrong\n",
            "results because of wrong clusters owing to the combination of dissimilar text parts [50]. The approaches of pdf2table,\n",
            "TableSeer and PDF-TREX Table Lines may have more than one text segment. According to Fang et al., this consider-\n",
            "ation may lead to under- or over-segmentation because it depends on predefined thresholds, spanning cells, and it would\n",
            "be difficult to distinguish between tables if a page contains more than one table. This approach cannot handle sparse\n",
            "tables in a well-mannered way. Border lines and rules play an important role in complex table layouts [25]. These are\n",
            "ignored in all approaches except those of Hassan and Baumgartner [58] and Fang et al. [25] for spotting text regions.\n",
            "\n",
            "The rules-based systems use logical inference for table detection. Mohemad et al. [50] propose a rules-based approach\n",
            "for measuring smallest distance between text chunks in order to minimize wrong cluster creation. They arrange recog-\n",
            "nized text and structure from PDF documents into ontology to assist the further reasoning process, as in Oro E and\n",
            "Ruffolo [60, 61]. However, JPEDAL is used for PDF document coordinate extraction. For result evaluation, the standard\n",
            "information extraction method of precision (PM), recall (RM) and F-measure has been applied. The technique is layout-\n",
            "based and cannot perform well for complex tables.\n",
            "\n",
            "Wrapper-based table detection is a subgraph of the document with some constraints using data instances for extract-\n",
            "ing related data [92]. Hassan and Baumgartner offer a wrapper-based approach for table detection in PDF documents\n",
            "but this method makes use of border lines, rules and text content separately. However, this approach does not verify gra-\n",
            "phic lines first, which produces false-positive lines resulting in false-positive tables [58]. To solve this limitation, Fang\n",
            "et al. propose a table detection method that makes use of both visual separators such as graphics lines and white spaces\n",
            "for unruled tables and irregular tables, for example, sparse tables, nested tables, tables wrapped in body paragraphs and\n",
            "minimizes false-positive table detection. Multicolumn pages are also handled for table detection. In contrast to Hassan\n",
            "and Baumgartner’s technique [58], here table spotting is done after verification of both candidate table content and\n",
            "visual separators, thus resulting in high accuracy. In other words, performance evaluation is needed in order to compare\n",
            "and select the best-suited method for a given application [25].\n",
            "\n",
            "4.2. Table representation approaches\n",
            "\n",
            "Different methods and techniques have been devised for table representation. Here by table representation we mean the\n",
            "formal manipulation of tables without any real understanding of their content [93]. Wang’s model is considered as the\n",
            "most common table model in literature for generating table images from logical structure descriptions, but the model does\n",
            "not describe footnotes or other text associated with a table (e.g. titles or captions). It is also unable to handle nested tables.\n",
            "The model assumes that stub-heads are empty, and headers are only positioned inside the box-head and stub of the table\n",
            "[71]. Similarly, Embley et al. propose a table detection model for web pages that uses domain-specific ontology for table\n",
            "recognition [93]. They admit the usability of Wang model for some table-specific tasks. Their contribution suggests some\n",
            "standard components for any table ontology. Amano and Asada propose a more versatile graph representation scheme for\n",
            "showing cell relationships of a table from documents. The graph is encoded in XML format using context-free grammar\n",
            "for table layouts [94]. Wang uses table ground truth and develops a tool for generating table element-containing docu-\n",
            "ments [95]. All these models cannot cover table-related information as well as document background information [21].\n",
            "\n",
            "Yildiz et al. carried out the first relative research on PDF for tables [48]. This technique uses a pdf2hmtl tool that\n",
            "returns text pieces and their absolute coordinates which are then utilized for table detection and decomposition. The tech-\n",
            "nique is heuristics-based and merges text elements defining single-line, multiline objects and multiline blocks. Finally,\n",
            "detected multiline blocks that may belong to the same table are merged [48]. The technique is limited as it assumes all\n",
            "pages to be single column. The assumptions that the table row contains more than one text segment may lead to under-\n",
            "or over-segmentation of tables. Sparse tables may lead to wrong results. Hurst presents a model that uses segmentation\n",
            "process for identifying PDF document parts [96]. The model also deals with table semantics as well [5]. TableSeer\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "49\n",
            "\n",
            "provides a universal metadata specification for tables for any document medium. Their ongoing task is to incorporate\n",
            "table data with Dublin Core to improve its searching process.\n",
            "\n",
            "4.3. Table classification approaches\n",
            "\n",
            "Table analysis after table extraction has been considered by some researchers [40, 43, 97–99]. Genuine tables have rela-\n",
            "tionships among cells in a two-dimensional grid and non-genuine tables are just clusters for viewing purposes only [45].\n",
            "Similarly, a classification data-table has correlation in cells and layout tables have no correlation, being are just for view-\n",
            "ing purposes only [108]. Hurst classifies tables into two classes where type 1 table implicit relationships are clear in the\n",
            "html document and type 2 tables are for data viewing only [96]. According to Pivk et al. [98], tables are of three layouts:\n",
            "one-dimensional, two-dimensional and complex tables. A one-dimensional table has at least one row of attribute cells\n",
            "above the rows of instance cells. A two-dimensional table has a rectangular area of instance cells appearing within col-\n",
            "umns. Complex tables might have features including partition data labels, over-expanded labels or a combination of these\n",
            "two. Yoshida et al. categorize tables into nine types according to table structure and their relative locations of attribute\n",
            "strings and value strings [99]. For more details about types the interested user may read [99].\n",
            "\n",
            "4.4. Search engines and tables\n",
            "\n",
            "Search engines are used for a variety of purposes including searching images, maps, videos, patents and document parts.\n",
            "Although table-related research has attained tremendous attention, table search has not grown enough. Pyreddy and\n",
            "Croft designed a character alignment graph (CAG) for TINTIN system to extract tables for information retrieval using a\n",
            "question-answering technique. This system indexes and searches tables [27]. Wang and Hu propose a system for storing\n",
            "extracted table data in databases for retrieving information through spoken language interface [45]. According to Wang\n",
            "and Hu, genuine tables are two-dimensional grids expressing logical relationships among cells. However, none of above-\n",
            "mentioned research works provide real table search. Recently, several online systems, including Illustrara [100] and\n",
            "BioText [101] perform searching, but tables are not treated very well, for example, it extracts a single table from a docu-\n",
            "ment and displays it multiple times instead of showing all page tables. Only TableSeer is a table search engine that can\n",
            "retrieve tables in response to user queries and supports automatic table metadata extraction.\n",
            "\n",
            "Obtaining the most relevant results among retrieved results is the most important issue that has been the focus of\n",
            "many researchers and contributors. This is the case where ranking comes forwards. Ranking results are normally based\n",
            "on query/page similarities, various retrieval models such as Vector Space Model with pivoted document length normali-\n",
            "zation [102], language modelling [103], Okapi BM formula [104] and ranking algorithms such as PageRank [105]. The\n",
            "information retrieval models and ranking algorithms provide unwanted and false-positive results in the case of table\n",
            "searching because these cannot recognize the importance of table terms and ignore term locations, table reference text,\n",
            "document quality, etc. [17]. TableSeer [51] also uses a ranking algorithm that extracts tables from documents using a\n",
            "box-cutting method [17] and applies this ranking algorithm on tables. It displays ranked results ordered by date, rele-\n",
            "vance and citation. The approach is limited because of low precision owing to the assumption that all tables have cap-\n",
            "tions. Thus tables having no caption are ignored by the search engines, which could lead to low recall. There are other\n",
            "related tasks such as table compression, table clustering and table margining; however, we do not consider them as they\n",
            "are beyond the scope of this paper.\n",
            "\n",
            "4.5. Datasets and metrics for evaluating table detection algorithms\n",
            "\n",
            "The evaluation of table detection algorithms is a big problem owing to the lack of standard datasets. There is no bench-\n",
            "mark/ground truth to evaluate experimental results; therefore no performance metrics could be achieved [12]. Precision\n",
            "and recall are commonly used as evaluation methods, but are not sufficient for handling all sorts of table detection errors.\n",
            "Luckily researchers have proposed some other evaluation methods for table detection in order to handle errors other than\n",
            "false-positive and false-negative detection. Hu et al. address an edit-distance-based measurement [110]. Shahab et al.\n",
            "propose a colour-encoding-based evaluation method [73]. Silva suggests absolute metrics completeness (proportion of\n",
            "completely identified terms of the total number of original terms) and purity (proportion of pure detected elements of all\n",
            "detected elements) used in ICDAR 2011 (table recognition competition) as performance metrics [68]. All evaluation\n",
            "methods discussed above can evaluate algorithms as a whole and cannot highlight detailed error descriptions with no\n",
            "improvement hints [12].\n",
            "\n",
            "Hu et al. collected 26 Wall Street Journal articles and email messages as a dataset [110]. The Silva dataset is com-\n",
            "posed of 22 PDF financial statements [73]. The UW-III dataset consists of 215 marked table zones in 110 pages. The\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "50\n",
            "\n",
            "dataset is commonly used but, except for bounding box information of the table region, no other structure information is\n",
            "provided [111]. Wang et al. provide a downloadable software tool package, and produced 1125 document image ground-\n",
            "truths, 565 table entities and 10,298 cell entities, but their dataset and ground-truth are not publicly available [14]. Fang\n",
            "et al. [12] provide a ground-truth general dataset, and propose evaluation metrics with publicly available source code for\n",
            "table detection algorithms. They define six general error types: fake, reduced, amplified, splitted, merged and missed.\n",
            "They evaluate three important table detection algorithms, namely TableSeer, pdf2table and their own algorithm [25].\n",
            "\n",
            "4.6. Table extraction and semantic annotation\n",
            "\n",
            "Table interpretation can be considered as finding missing information from the document itself or from external sources\n",
            "[96]. Table semantics extraction has become a dominant field of research. Hurst identifies categories and relationships.\n",
            "For category identification he joins the cells of the same category together and then identifies relationships among cells.\n",
            "He proposes several relationships such as nominal super-type, qualitative super-type, partitive, units of measurement and\n",
            "quantitative. He proposes classification of relationships based on semantic types of the content (dates, numbers, units of\n",
            "measure, years) as well as on the comparison of table content with rest of text in the document and the presence of cer-\n",
            "tain keywords [96].\n",
            "\n",
            "Ferguson worked on category and relation identification in tables and mapped values to ontology, comparing these\n",
            "values with surrounding text. However, this effort is context-dependent and cannot be used out of context [41]. Another\n",
            "approach is the identification of partitive relationships between the content of cells. With these, a hierarchical tree can be\n",
            "built based on table attributes. This tree is then compared word by word with a manually built collection of all possible\n",
            "alternatives to name the concepts they wish to extract [23]. Context ontology can also be used for matching table content\n",
            "with ontology for finding functionality of content in a table, which after structural analysis can be used in table interpreta-\n",
            "tion [112]. Similarly, TANGO [72], short for Table ANalysis for Generating Ontologies, works mostly within the geopo-\n",
            "litical domain. The aim is to semi-automatically generate ontologies for user-chosen domain using software tools as well\n",
            "as user direction and correction. For this purpose, users utilize domain concept-related tables, thus raw tables become\n",
            "interpreted tables.\n",
            "\n",
            "Tijerino et al. present a more detailed description (without experimentation) of their vision of how TANGO should\n",
            "work to automatically generate Semantic Web ontologies from either lists or tables [72]. Embley et al. match table data\n",
            "against their self-created context ontology. This mapping can be direct; merging or splitting of the column’s content may\n",
            "be required. They claim that by changing the context ontology they can adapt to any context [62]. Jha and Nagy did not\n",
            "make use of ontologies; rather they developed a tool based on user involvement for finding categories and relationships\n",
            "[76]. Lynn and Embley developed a semantic enrichment algorithm whose input is canonicalized tables obtained using\n",
            "Jha and Nagy’s Wang Notation Tool. A lexicon and a domain concept-rich library of regular expressions is used for\n",
            "mappings, relationships and constraints discovery [77]. Similarly, Hignette et al. make use of ontology for defining\n",
            "tables. The approach finds cosine similarity between ontology terms and the title and content of the column. It tests table\n",
            "compliance with ontology by relevant matches and fuzzy measure of respective relevance [78]. Table 3 shows that the\n",
            "use of a pre-compiled catalogue for table annotation remains the dominant approach in the literature. Sometimes entity\n",
            "annotation needs semantic enrichment from external knowledge resources [69, 70]. Determining the main concepts asso-\n",
            "ciated with tables can be done using single-entity column values and remaining column headers [84] where concept\n",
            "extraction is done using the Probase knowledge base [113]. However, the approach is limited as it deals with columns\n",
            "not with cells and it only aims at concepts associated with tables. The knowledge base used is not dynamic like that of\n",
            "DBpedia, YAGO or Linked Open Data (LOD) cloud.\n",
            "\n",
            "YAGO [114] can be used for extracting multiple labels for each column in a table and discovering relations between\n",
            "columns [85]. Both concept identification for columns and relation identification are based on maximum likelihood\n",
            "hypotheses similar to the one presented in Limaye et al. [79], that is, the best class label (or relation) is one that maxi-\n",
            "mizes the probability of values given by class label (or relation) for the column. This approach uses YAGO ontology,\n",
            "which is built on top of Wikipedia [115], to label cells with entity IDs, and to label table columns as well as finding bin-\n",
            "ary relationships between columns using probabilistic graphical model-based framework. A single label is chosen from\n",
            "YAGO and the algorithm searches for maximum values of variables, leveraging their joint probability. The dataset used\n",
            "in this approach is the Wiki manual, which is publicly available [79]. The goal is to boost the joint inference about each\n",
            "table based on labels. The approach is limited because of using YAGO for finding relationships as it includes a small\n",
            "fraction of labels and less than 100 binary relationships [116]. Another approach processes web pages for normalizing\n",
            "and interpreting tables for determining attribute–value pair formation [117].\n",
            "\n",
            "Web pages can also be used for table annotation as web pages are richer than YAGO; however, this work is limited\n",
            "to columns and does not deal with cells. Both this approach and the approach presented by Limaye et al. [79] are unable\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "Table 3. Semantics extraction techniques.\n",
            "\n",
            "51\n",
            "\n",
            "Document type\n",
            "\n",
            "HTML\n",
            "\n",
            "PDF\n",
            "\n",
            "Text\n",
            "\n",
            "Image\n",
            "\n",
            "XLS\n",
            "\n",
            "Tool based\n",
            "Ontological based\n",
            "Pre compiled catalogue\n",
            "LOD datasets\n",
            "Web pages\n",
            "RDF triple\n",
            "By surrounding text\n",
            "Unknown entities\n",
            "Snippets\n",
            "Kb enrichment\n",
            "Ontology enrichment\n",
            "Document corpus\n",
            "Word net\n",
            "Multiple domain\n",
            "Data_ Frame Library\n",
            "\n",
            "[76, 77]\n",
            "[40, 62, 72, 78, 82, 106, 107]\n",
            "[18, 83–85, 109]\n",
            "[79, 82, 109]\n",
            "[85]\n",
            "[82, 83]\n",
            "[80, 86]\n",
            "[18, 83]\n",
            "[83]\n",
            "[83]\n",
            "—\n",
            "—\n",
            "[77, 109]\n",
            "—\n",
            "[77]\n",
            "\n",
            "—\n",
            "[41, 60]\n",
            "[81]\n",
            "—\n",
            "—\n",
            "[81, 109]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "[60]\n",
            "\n",
            "[60]\n",
            "[81]\n",
            "—\n",
            "\n",
            "[5, 23, 70, 96]\n",
            "[9]\n",
            "[9, 70]\n",
            "—\n",
            "—\n",
            "—\n",
            "[69, 75]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "[70]\n",
            "[9, 69, 70, 75]\n",
            "—\n",
            "—\n",
            "\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "[71]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "\n",
            "—\n",
            "[107, 108]\n",
            "[88]\n",
            "—\n",
            "—\n",
            "[87, 88]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "\n",
            "to annotate new entities not listed in the catalogue. All of the mentioned systems are either manual or semi-automated,\n",
            "working with string values or ignoring literals. To the best of our knowledge there is no tool that truly and completely\n",
            "automates interpretation of a table and thus the output of these systems is raw strings. Therefore no accurate RDF linked\n",
            "data are obtained. Amin et al. [80] proposed an algorithm that labels each column of a table using a Wikipedia best\n",
            "describing category based on column content. This technique does not deal with ambiguous results from Wikipedia and\n",
            "also ignores entities that are unknown to Wikipedia. Another related but rather different approach is the domain-\n",
            "independent interpretation of data in which an automated interpretation of a table is carried out that focuses on column\n",
            "headers, row values and relations between columns. The technique is based on graphical modelling and probabilistic rea-\n",
            "soning, providing results as RDF triples. These also focus on literals and work across multiple domain-web tables, and\n",
            "medical and open government data [81].\n",
            "\n",
            "None of above-mentioned methods and proposed techniques provides domain-independent interpretation of tables.\n",
            "For table annotation Venetis crawls web pages using regular expressions to obtain class information [85]. This web-\n",
            "crawled database has a wider coverage than any modelled ontological database, but suffers from more noise [118]. The\n",
            "above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or\n",
            "information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known,\n",
            "whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalo-\n",
            "gue is addressed by some researchers [18, 73, 83]. In these approaches, missing entities annotation is done using text clas-\n",
            "sifiers over snippets returned by search engines [18], using ITEM tool for extracting tables whose structure resembles the\n",
            "RDF knowledge base where new tuples are identified and stored in knowledge base [83] or using ITEM but not using the\n",
            "RDF knowledge base for detecting new entities in tables, Google Fusion Tables (GFT) [73]. The latter approach dis-\n",
            "covers new entities of tables but it is not essential that schema of entities must match the database. The latest and richest\n",
            "open knowledge bases are YAGO [114], DBpedia [115] and Freebase.21 In the literature, tables are annotated by pre-\n",
            "compiled catalogue of entities, types of relationships [18, 81, 85], LOD datasets [79] or ontologies [61]. Probase contains\n",
            "2.7 million concepts and is estimated to include concepts/entities that occur in more than 80% of web searches [86].\n",
            "\n",
            "GFT is a popular web application provided by Google that allows people, including those with no database expertise,\n",
            "to manage their data [18]. Cimiano and Vo¨lker [75] use WordNet for annotation purposes and Fleischman and Hovy\n",
            "[69] use a document corpus for entity annotation. Ontologies can be used for extracting information from tables. One\n",
            "approach is recognizing GFT tables from specific fields using ontology to extract information from tables and filling the\n",
            "ontology with the extracted information [86]. A similar approach is the use of the ITEM tool without using the RDF\n",
            "knowledge base for new entity identification in GFT tables. It identifies new entities by applying a trained text classifier\n",
            "on snippets returned by search engines (Microsoft Bing API). Ambiguous results from snippets about entity description\n",
            "are not handled by this approach [86]. Table information can also be used in enriching knowledge sources. In this regard,\n",
            "one approach can be the use of a catalogue, but entities not present in the catalogue cannot be identified [73]. Tables\n",
            "whose structure matches schema are retrieved and tuples that are not present in the database are added. The aim is to fill\n",
            "an OWL ontology, which is used in data identification and extraction process, and to convert the obtained data into\n",
            "RDF. Normally text surrounding a table is very important for clarifying table semantics if the table itself cannot clarify\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "52\n",
            "\n",
            "all the concepts. Sometimes entities are context-dependent and can be annotated with surrounding text using domain\n",
            "ontology [119]. However, the technique is limited owing to weak programing and limited domain ontology.\n",
            "\n",
            "Table 3 shows that no single approach is perfect for annotating all types of tables in all domains. Selection of the best\n",
            "possible approach in any domain depends on user requirements and available annotation resources. If table annotation\n",
            "using surrounding text is required, then a rule-based approach will give good performance. For annotation of table enti-\n",
            "ties using online knowledge sources, an active learning technique would be best choice as it saves time in the rule-\n",
            "building process. Most methods use knowledge from outside the system; however, the available knowledge sources are\n",
            "not sufficient to cover all domains. Therefore, full context-independent interpretation of tables is not always true. Table 3\n",
            "shows that semantic analysis of PDF tables is quite recent. Finding semantic similarity between tables is a line of oppor-\n",
            "tunity as almost no work has been found in the literature in this direction. Few authors have targeted the interpretation\n",
            "task. Authors either use context-specific interpretation, which works well for specific context but cannot be adopted for\n",
            "tables in general, or they use context-independent interpretation, which makes them unable to gain full fruit of interpreta-\n",
            "tion. Ontological-based approaches are also not able to cover domain independent table interpretation. For domain-\n",
            "specific interpretation they also requires full grasp of domain-specific knowledge for good table annotation. In the table\n",
            "interpretation case a mixed technique should be adopted using text surrounding the table and online knowledge sources\n",
            "with search engine snippets. Also, the integration of several knowledge bases, each containing domain-specific data,\n",
            "might be worthwhile.\n",
            "\n",
            "5. Conclusion and future work\n",
            "\n",
            "The importance of tables in web pages, books and other scholarly documents cannot be ignored while searching them. A\n",
            "huge and rich literature is available highlighting different aspects of table detection, extraction, exploration, classification\n",
            "and annotation. In this paper we highlighted this importance, contributing an evaluation framework for comparing differ-\n",
            "ent information extraction tools and techniques that could be used in processing documents containing tables. The most\n",
            "important aspect is the contribution of the state of the art in table-related research. We came to the conclusion that table\n",
            "identification and extraction tools should be improved in precision and performance because table annotation directly\n",
            "depends on the results of the extraction tools. We highlighted the shortcomings of current rule-based, heuristics-based,\n",
            "wrapper-based and statistical-based techniques for handling tables.\n",
            "\n",
            "By analysing the available table annotation techniques it can be concluded that finding similarities between tables and\n",
            "the measure of their distance, referencing tables in the same or other documents, text/table conversion, ER/table conver-\n",
            "sion, standard datasets and evaluation matrices, making high-performance generalized table annotation algorithms, table\n",
            "recommendation systems, the role of tables in document summarization, classification, and clustering, fully automated\n",
            "ontology generation for table annotation, optimal ranking and table search algorithms are potential research areas in the\n",
            "field. The fact that no significant work has so far been contributed on book table extraction and annotation necessitates\n",
            "the adoption og mechanisms for handling book tables, whether these are present in PDF or other similar formats includ-\n",
            "ing e-pub, DjVu and chm.\n",
            "\n",
            "A number of book-searching solutions and book search engines are available; however, they are not efficient and pre-\n",
            "cise enough to cope with the needs of all book-searching users. Tables being an important component of books and other\n",
            "scholarly documents, their semantics need to be incorporated into the search process so that one can specify a particular\n",
            "table in a book and ask the search engines to find related tables in other books that conceptually summarize, elaborate\n",
            "and compare the concepts and data presented in the selected table. With the incorporation of such semantics, ‘under-\n",
            "standing’ of a particular table will become much easier and readers will not have to manually search for books, which\n",
            "will reduce the resulting cognitive load. Also the need here is the implementation of a true book search engine that can\n",
            "find, annotate and rank book tables so that similar books can be searched on certain parameters. A combined approach\n",
            "should be applied for book table annotation using online knowledge sources and semantic analysers. The entities of book\n",
            "tables which are missing should be annotated using search engine results and by extracting paragraphs surrounding\n",
            "tables. There is a serious need for PDF table extraction and annotation tools that could extract tables from PDF docu-\n",
            "ments with higher accuracy and annotate them using concepts from the surrounding text, other points of reference and\n",
            "external sources.\n",
            "\n",
            "Funding\n",
            "\n",
            "This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\f53\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "Notes\n",
            "\n",
            "1. http://www.greenstone.org\n",
            "2. http://pdfbox.apache.org\n",
            "3. http://itextpdf.com\n",
            "4. http://www.icepdf.org\n",
            "5. https://github.com/ashima/pdf-table-extract\n",
            "6. http://tabula.nerdpower.org\n",
            "7. http://www.snapfiles.com/get/pdf2html.html\n",
            "8. http://www.verypdf.com/app/pdf-table-extractor\n",
            "9. http://www.adobe.com/products/catalog/services.html\n",
            "\n",
            "10. http://ieg.ifs.tuwien.ac.at/projects/pdf2table\n",
            "11. http://www.soliddocuments.com\n",
            "12. http://www.pdf-tools.com\n",
            "13. http://www.pdflib.com/products/tet\n",
            "14. http://pdftransformer.abbyy.com\n",
            "15. http://okular.kde.org\n",
            "16. http://finereader.abbyy.com/corporate/\n",
            "17. http://www.adobe.com/products/acrobatpro/features.html\n",
            "18. http://www.nuance.com/for-business/by-product/omnipage/ultimate/index.htm\n",
            "19. http://www.nitropdf.com/\n",
            "20. http://www.visionbib.com/bibliography/char969.html\n",
            "21. http://www.freebase.com\n",
            "\n",
            "References\n",
            "\n",
            "[1] Yıldız B. Information extraction–utilizing table patterns: Master’s thesis, Vienna University of Technology, 2004.\n",
            "[2] Bienz T, Cohn R and Meehan J. Portable document format reference manual. Addison-Wesley Reading, MA, USA, 1993.\n",
            "[3] Merz T. Web Publishing with Acrobat/PDF. Berlin: Springer, 1998.\n",
            "[4] Pitfalls CFPTXMWAT. White paper, 2003.\n",
            "[5] Hurst M. Towards a theory of tables. International Journal of Document Analysis and Recognition (IJDAR) 2006; 8(2–3): 123–\n",
            "\n",
            "131.\n",
            "\n",
            "[6] Long V, Dale R and Cassidy S (eds). A model for detecting and merging vertically spanned table cells in plain text documents.\n",
            "\n",
            "In: Proceedings eighth international conference on document analysis and recognition. New York: IEEE, 2005.\n",
            "\n",
            "[7] Peterman C, Chang CH and Alam H (eds). A system for table understanding. In: Proceedings of the symposium on document\n",
            "\n",
            "image understanding technology (SDIUT’97), 1997.\n",
            "\n",
            "[8] Cameron JP. A cognitive model for tabular editing. Ohio State University, Computer & Information Science Research Center,\n",
            "\n",
            "1989.\n",
            "\n",
            "[9] Silva AC, Jorge AM and Torgo L. Design of an end-to-end method to extract information from tables. International Journal of\n",
            "\n",
            "Document Analysis and Recognition (IJDAR) 2006; 8(2–3): 144–171.\n",
            "\n",
            "[10] Lopresti D and Nagy G. A tabular survey of automated table processing. In: Graphics recognition recent advances. Berlin:\n",
            "\n",
            "Springer, 2000, pp. 93–120.\n",
            "\n",
            "[11] Wong W, Martinez D and Cavedon L (eds). Extraction of named entities from tables in gene mutation literature. In:\n",
            "Proceedings of the workshop on current trends in biomedical natural language processing. Association for Computational\n",
            "Linguistics, 2009.\n",
            "\n",
            "[12] Fang J, Tao X, Tang Z, Qiu R and Liu Y (eds). Dataset, ground-truth and performance metrics for table detection evaluation. In:\n",
            "\n",
            "10th IAPR international workshop on document analysis systems (DAS). New York: IEEE, 2012.\n",
            "\n",
            "[13] Long V. An agent-based approach to table recognition and interpretation. Macquarie University Sydney, Australia, 2010.\n",
            "[14] Wang Y, Phillips IT and Haralick RM. Table structure understanding and its performance evaluation. Pattern Recognition\n",
            "\n",
            "2004; 37(7): 1479–1497.\n",
            "\n",
            "[15] Lewandowsky S and Spence I. The perception of statistical graphs. Sociological Methods & Research 1989; 18(2–3): 200–242.\n",
            "[16] Vanoirbeek C (ed.). Formatting structured tables. In: EP92, Proceedings of electronic publishing, 1992.\n",
            "[17] Liu Y. Tableseer: Automatic table extraction, search, and understanding. The Pennsylvania State University, 2009.\n",
            "[18] Quercini G and Reynaud C (eds). Entity discovery and annotation in tables. In: Proceedings of the 16th international conference\n",
            "\n",
            "on extending database technology. New York: ACM, 2013.\n",
            "\n",
            "[19] Schmoekel I. PDF-analyzer pro 4.0. Software-development and distribution. AchimUesen, Germany, 2010, Vol. 1, pp. 1–11.\n",
            "[20] Amyuni T. PDF Vol. 2010. Montreal: Amyuni Technologies, 2010.\n",
            "[21] Liu Y, Bai K, Mitra P and Giles CL (eds). Tableseer: Automatic table metadata extraction and searching in digital libraries. In:\n",
            "\n",
            "Proceedings of the 7th ACM/IEEE-CS joint conference on digital libraries. New York: ACM, 2007.\n",
            "\n",
            "[22] Friedman DKaN. Probabilistic graphical models: Principles and techniques. Cambridge, MA: MIT Press, 2009.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "54\n",
            "\n",
            "[23] Kornfeld W and Wattecamps J (eds). Automatically locating, extracting and analyzing tabular data. In: Proceedings of the 21st\n",
            "\n",
            "annual international ACM SIGIR conference on research and development in information retrieval. New York: ACM, 1998.\n",
            "\n",
            "[24] Embley DW, Lopresti D and Nagy G. Table-processing paradigms: A research survey. International Journal on Document\n",
            "\n",
            "Analysis and Recognition 2006; 8(2): 66–86.\n",
            "\n",
            "[25] Fang J, Gao L, Bai K, Qiu R, Tao X and Tang Z (eds). A table detection method for multipage pdf documents via visual sepera-\n",
            "tors and tabular structures. In: International conference on document analysis and recognition (ICDAR). New York: IEEE,\n",
            "2011.\n",
            "\n",
            "[26] Zanibbi R, Blostein D and Cordy JR. A survey of table recognition. Document Analysis and Recognition 2004; 7(1): 1–16.\n",
            "[27] Pyreddy P and Croft WB (eds). Tintin: A system for retrieval in text tables. In: Proceedings of the second ACM international\n",
            "\n",
            "conference on digital libraries. New York: ACM, 1997.\n",
            "\n",
            "[28] Rus D and Summers K. Using white space for automated document structuring. Ithaca, NY: Cornell University, 1994.\n",
            "[29] Klein B, Gokkus S, Kieninger T and Dengel A (eds). Three approaches to ‘industrial’ table spotting. In: Proceedings of the sixth\n",
            "\n",
            "international conference on document analysis and recognition. New York: IEEE, 2001.\n",
            "\n",
            "[30] Hu J, Kashi RS, Lopresti DP and Wilfong G (eds). Medium-independent table detection. Electronic Imaging. International\n",
            "\n",
            "Society for Optics and Photonics, 1999.\n",
            "\n",
            "[31] Ng HT, Lim CY and Koo JLT (eds). Learning to recognize tables in free text. In: Proceedings of the 37th annual meeting of the\n",
            "\n",
            "Association for Computational Linguistics on Computational Linguistics. Association for Computational Linguistics, 1999.\n",
            "\n",
            "[32] Kieninger TG (ed.). Table structure recognition based on robust block segmentation. In: Photonics west’98: Electronic imaging.\n",
            "\n",
            "International Society for Optics and Photonics, 1998.\n",
            "\n",
            "[33] Pinto D, Branstein M, Coleman R, Croft WB, King M, Li W et al. (eds). QuASM: a system for question answering using semi-\n",
            "\n",
            "structured data. In: Proceedings of the 2nd ACM/IEEE-CS joint conference on Digital libraries. New York: ACM, 2002.\n",
            "\n",
            "[34] Pinto D, McCallum A, Wei X and Croft WB (eds). Table extraction using conditional random fields. In: Proceedings of the\n",
            "26th annual international ACM SIGIR conference on Research and development in informaion retrieval. New York: ACM,\n",
            "2003.\n",
            "\n",
            "[35] Green EA and Krishnamoorthy MS. Model-based analysis of printed tables. In: Graphics Recognition Methods and\n",
            "\n",
            "Applications. Berlin: Springer, 1996, pp. 80–91.\n",
            "\n",
            "[36] Tupaj S, Shi Z, Chang CH and Alam H. Extracting tabular information from text files. EECS Department, Tufts University,\n",
            "\n",
            "Medford, USA. 1996.\n",
            "\n",
            "[37] Shamilian JH, Baird HS and Wood TL (eds). A retargetable table reader. In: Proceedings of the fourth international conference\n",
            "\n",
            "on document analysis and recognition. New York: IEEE, 1997.\n",
            "\n",
            "[38] Kieninger T and Dengel A (eds). A paper-to-HTML table converting system. In: Proceedings of document analysis systems\n",
            "\n",
            "(DAS), 1998.\n",
            "\n",
            "[39] Cesarini F, Marinai S, Sarti L and Soda G (eds). Trainable table location in document images. In: Proceedings 16th interna-\n",
            "\n",
            "tional conference on pattern recognition. New York: IEEE, 2002.\n",
            "\n",
            "[40] Wang Y and Hu J. Detecting tables in html documents. In: Document analysis systems V. Berlin: Springer, 2002, pp. 249–260.\n",
            "[41] Ferguson D (ed.). Parsing financial statements efficiently and accurately using C and Prolog. In: Proceedings of the fifth interna-\n",
            "\n",
            "tional conference on the practical application of Prolog, London, 1997.\n",
            "\n",
            "[42] Ramel J-Y, Crucianu M, Vincent N and Faure C (eds). Detection, extraction and representation of tables. In: proceedings\n",
            "\n",
            "seventh international conference on document analysis and recognition. New York: IEEE, 2003.\n",
            "\n",
            "[43] Chen H-H, Tsai S-C and Tsai J-H (eds). Mining tables from large scale HTML texts. In: Proceedings of the 18th conference on\n",
            "\n",
            "Computational linguistics, Volume 1. Association for Computational Linguistics, 2000.\n",
            "\n",
            "[44] Cohen WW, Hurst M and Jensen LS (eds). A flexible learning system for wrapping tables and lists in HTML documents. In:\n",
            "\n",
            "Proceedings of the 11th international conference on World Wide Web. New York: ACM, 2002.\n",
            "\n",
            "[45] Wang Y and Hu J (eds). A machine learning based approach for table detection on the web. In: Proceedings of the 11th interna-\n",
            "\n",
            "tional conference on World Wide Web. New York: ACM, 2002.\n",
            "\n",
            "[46] Zhang X-w, Lyu MR and Dai G-z. Extraction and segmentation of tables from Chinese ink documents based on a matrix model.\n",
            "\n",
            "Pattern Recognition 2007; 40(7): 1855–1867.\n",
            "\n",
            "[47] Nagy G and Tamhankar M. VeriClick: An efficient tool for table format verification. In: IS&T/SPIE electronic imaging.\n",
            "\n",
            "International Society for Optics and Photonics, 2012, p. 82970M.\n",
            "\n",
            "[48] Yildiz B, Kaiser K and Miksch S (eds). pdf2table: A method to extract table information from PDF files. IICAI, 2005.\n",
            "[49]\n",
            "\n",
            "Jiang D and Yang X (eds). Converting PDF to HTML approach based on text detection. In: Proceedings of the 2nd international\n",
            "conference on interaction sciences: information technology, culture and human. New York: ACM, 2009.\n",
            "\n",
            "[50] Mohemad R, Hamdan AR, Othman ZA and Noor NM. Automatic document structure analysis of structured PDF files.\n",
            "\n",
            "International Journal of New Computer Architectures and their Applications (IJNCAA), 2011, Vol. 1(2): 404–411.\n",
            "\n",
            "[51] Liu Y, Bai K, Mitra P and Giles CL (eds). Tablerank: A ranking algorithm for table search and retrieval. In: Proceedings of the\n",
            "\n",
            "national conference on artificial intelligence, Menlo Park, CA/Cambridge, MA: AAAI Press/MIT Press, 2007.\n",
            "\n",
            "[52] Hurst M (ed.). Layout and language: An efficient algorithm for detecting text blocks based on spatial and linguistic evidence.\n",
            "\n",
            "In: Photonics west 2001 – Electronic imaging. International Society for Optics and Photonics, 2000.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "55\n",
            "\n",
            "[53] Douglas S, Hurst M and Quinn D (eds). Using natural language processing for identifying and interpreting tables in plain text.\n",
            "\n",
            "In: Proceedings of the fourth annual symposium on document analysis and information retrieval. Citeseer, 1995.\n",
            "\n",
            "[54] Shin J and Guerette N (eds). Table recognition and evaluation. In: Class of 2005 senior conference on natural language process-\n",
            "\n",
            "ing. Citeseer, 2005.\n",
            "\n",
            "[55] Mandal S, Chowdhury S, Das AK and Chanda B. A simple and effective table detection system from document images.\n",
            "\n",
            "International Journal of Document Analysis and Recognition (IJDAR) 2006; 8(2–3): 172–182.\n",
            "\n",
            "[56] Liu Y, Mitra P, Giles CL and Bai K (eds). Automatic extraction of table metadata from digital documents. In: Proceedings of\n",
            "\n",
            "the 6th ACM/IEEE-CS joint conference on digital libraries. New York: ACM, 2006.\n",
            "\n",
            "[57] Li J, Tang J, Song Q and Xu P. Table detection from plain text using machine learning and document structure. In: Frontiers of\n",
            "\n",
            "WWW research and development – APWeb 2006. Berlin: Springer, 2006, pp. 818–823.\n",
            "\n",
            "[58] Hassan T and Baumgartner R (eds). Table recognition and understanding from pdf files. In: Ninth international conference on\n",
            "\n",
            "document analysis and recognition, ICDAR 2007. New York: IEEE, 2007.\n",
            "\n",
            "[59] Liu Y, Mitra P and Giles CL (eds). Identifying table boundaries in digital documents via sparse line detection. In: Proceedings\n",
            "\n",
            "of the 17th ACM conference on information and knowledge management. New York: ACM, 2008.\n",
            "\n",
            "[60] Oro E and Ruffolo M (eds). Pdf-trex: An approach for recognizing and extracting tables from pdf documents. In: ICDAR’09:\n",
            "\n",
            "10th international conference on document analysis and recognition. New York: IEEE, 2009.\n",
            "\n",
            "[61] Oro E and Ruffolo M (eds). Xonto: An ontology-based system for semantic information extraction from pdf documents. In:\n",
            "\n",
            "ICTAI’08: 20th IEEE international conference on tools with artificial intelligence. New York: IEEE, 2008.\n",
            "\n",
            "[62] Embley DW, Tao C and Liddle SW. Automating the extraction of data from HTML tables with unknown structure. Data &\n",
            "\n",
            "Knowledge Engineering 2005; 54(1): 3–28.\n",
            "\n",
            "[63] Gatterbauer W, Bohunsky P, Herzog M, Kru¨pl B and Pollak B (eds). Towards domain-independent information extraction from\n",
            "\n",
            "web tables. In: Proceedings of the 16th international conference on World Wide Web. New York: ACM, 2007.\n",
            "\n",
            "[64] Silva AC (ed.). Learning rich hidden Markov models in document analysis: Table location. In: ICDAR, 2009.\n",
            "[65] Lafferty J, McCallum A and Pereira FC. Conditional random fields: Probabilistic models for segmenting and labeling sequence\n",
            "\n",
            "data, 2001.\n",
            "\n",
            "[66] Hurst M (ed.). Layout and language: Challenges for table understanding on the web. In: Proceedings of the international work-\n",
            "\n",
            "shop on Web document analysis. Citeseer, 2001.\n",
            "\n",
            "[67] Wei X, Croft B and McCallum A. Table extraction for answer retrieval. Information Retrieval 2006; 9(5): 589–611.\n",
            "[68] Silva AC (ed.). New metrics for evaluating performance in document analysis tasks – application to the table case. In: ICDAR,\n",
            "\n",
            "2007.\n",
            "\n",
            "[69] Fleischman M and Hovy E (eds). Fine grained classification of named entities. In: Proceedings of the 19th international confer-\n",
            "\n",
            "ence on Computational linguistics – Vol. 1. Association for Computational Linguistics, 2002.\n",
            "\n",
            "[70] Ganti V, Ko¨nig AC and Vernica R (eds). Entity categorization over large document collections. In: Proceedings of the 14th\n",
            "\n",
            "ACM SIGKDD international conference on knowledge discovery and data mining. New York: ACM, 2008.\n",
            "\n",
            "[71] Wang X and Wood D. Tabular abstraction, editing, and formatting. Citeseer, 1996.\n",
            "[72] Tijerino YA, Embley DW, Lonsdale DW, Ding Y and Nagy G. Towards ontology generation from tables. World Wide Web\n",
            "\n",
            "2005; 8(3): 261–285.\n",
            "\n",
            "[73] Shahab A, Shafait F, Kieninger T and Dengel A (eds). An open approach towards the benchmarking of table structure recogni-\n",
            "\n",
            "tion systems. In: Proceedings of the 9th IAPR international workshop on document analysis systems. New York: ACM, 2010.\n",
            "\n",
            "[74] Go¨bel M, Hassan T, Oro E and Orsi G (eds). A methodology for evaluating algorithms for table understanding in PDF docu-\n",
            "\n",
            "ments. In: Proceedings of the 2012 ACM symposium on document engineering. New York: ACM, 2012.\n",
            "\n",
            "[75] Cimiano P and Vo¨lker J (eds). Towards large-scale, open-domain and ontology-based named entity classification. In:\n",
            "\n",
            "Proceedings of the international conference on recent advances in natural language processing (RANLP), 2005.\n",
            "Jha P. Wang notation tool: A layout independent representation of tables. Rensselaer Polytechnic Institute, 2008.\n",
            "\n",
            "[76]\n",
            "[77] Lynn S and Embley DW. Semantically conceptualizing and annotating tables. In: The Semantic Web. Berlin: Springer, 2008,\n",
            "\n",
            "pp. 345–359.\n",
            "\n",
            "[78] Hignette G, Buche P, Dibie-Barthe´lemy J and Haemmerle´ O. Fuzzy annotation of web data tables driven by a domain ontology.\n",
            "\n",
            "In: The Semantic Web: Research and applications. Berlin: Springer, 2009, pp. 638–653.\n",
            "\n",
            "[79] Limaye G, Sarawagi S and Chakrabarti S. Annotating and searching web tables using entities, types and relationships. In:\n",
            "\n",
            "Proceedings of the VLDB endowment, 2010; Vol. 3(1–2), pp. 1338–1347.\n",
            "\n",
            "[80] Amin MS, Bhattacharjee A and Jamil H (eds). Wikipedia driven autonomous label assignment in wrapper induced tables with\n",
            "\n",
            "missing column names. In: Proceedings of the 2010 ACM symposium on applied computing. New York: ACM, 2010.\n",
            "\n",
            "[81] Mulwad V, Finin T and Joshi A (eds). Generating linked data by inferring the semantics of tables. In: VLDS, 2011.\n",
            "[82] Mulwad V. T2LD – An automatic framework for extracting, interpreting and representing tables as Linked Data. University of\n",
            "\n",
            "Maryland, 2010.\n",
            "\n",
            "[83] Guo X, Chen Y, Chen J and Du X. ITEM: Extract and integrate entities from tabular data to RDF knowledge base. In:\n",
            "APWeb’11: Proceedings of the 13th Asia-Pacific Web conference on Web technologies and applications. Berlin: Springer,\n",
            "2011, pp. 400–411.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "56\n",
            "\n",
            "[84] Wang J, Wang H, Wang Z and Zhu KQ. Understanding tables on the web. In: Conceptual modeling. Berlin: Springer, 2012, pp.\n",
            "\n",
            "141–155.\n",
            "\n",
            "[85] Venetis P, Halevy A, Madhavan J, Pasxca M, Shen W, Wu F et al. Recovering semantics of tables on the web. In: Proceedings\n",
            "\n",
            "of the VLDB endowment, 2011; Vol. 4(9), pp. 528–538.\n",
            "\n",
            "[86] Quercini G and Reynaud C (eds). Des donne´es tabulaires a` RDF: l’extraction de donne´es de Google Fusion Tables. In: Atelier\n",
            "\n",
            "Ontologies et Jeux de Donne´es pour e´valuer le Web Se´mantique (OJD) associe´ a` IC’2012, 2012.\n",
            "\n",
            "[87] Han L, Finin T, Parr C, Sachs J and Joshi A. RDF123: From spreadsheets to RDF. In: The Semantic Web – ISWC. Berlin:\n",
            "\n",
            "Springer, 2008, pp. 451–466.\n",
            "\n",
            "[88] Van Assem M, Rijgersberg H, Wigham M and Top J. Converting and annotating quantitative data tables. In: The Semantic Web\n",
            "\n",
            "– ISWC. Berlin: Springer, 2010, pp. 16–31.\n",
            "\n",
            "[89] Kieninger T and Dengel A (eds). Applying the T-RECS table recognition system to the business letter domain. In: Proceedings\n",
            "\n",
            "sixth international conference on document analysis and recognition. New York: IEEE, 2001.\n",
            "\n",
            "[90] Pereira FSaF. Shallow parsing with conditional random fields, 2003.\n",
            "[91] McCallum A and Li W (eds). Early results for named entity recognition with conditional random fields, feature induction and\n",
            "web-enhanced lexicons. In: Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003, Vol. 4.\n",
            "Association for Computational Linguistics, 2003.\n",
            "\n",
            "[92] Gao L, Tang Z, Lin X, Liu Y, Qiu R and Wang Y (eds). Structure extraction from PDF-based book documents. In: Proceedings\n",
            "\n",
            "of the 11th annual international ACM/IEEE joint conference on digital libraries. New York: ACM, 2011.\n",
            "\n",
            "[93] Embley DW, Lopresti D and Nagy G. Notes on contemporary table recognition. In: Document analysis systems VII. Berlin:\n",
            "\n",
            "Springer, 2006, pp. 164–175.\n",
            "\n",
            "[94] Amano A and Asada N (eds). Graph grammar based analysis system of complex table form document. In: ICDAR. Citeseer,\n",
            "\n",
            "2003.\n",
            "\n",
            "[95] Wang Y, Phillips IT and Haralick R (eds). Automatic table ground truth generation and a background-analysis-based table struc-\n",
            "ture extraction method. In: Proceedings sixth international conference on document analysis and recognition. New York: IEEE,\n",
            "2001.\n",
            "\n",
            "[96] Hurst MF. The interpretation of tables in texts, 2000.\n",
            "[97] Wang C, Xie X, Wang W and Ma W-Y. Improving web browsing on small devices based on table classification. In: Advances\n",
            "\n",
            "in multimedia information processing – PCM 2004. Berlin: Springer, 2005, pp. 88–95.\n",
            "\n",
            "[98] Pivk A, Cimiano P and Sure Y. From tables to frames. Berlin: Springer, 2004.\n",
            "[99] Yoshida M, Torisawa K and Tsujii J. A method to integrate tables of the world wide web. In: Proceedings of the international\n",
            "\n",
            "workshop on Web document analysis. WDA, 2001, pp. 31–34.\n",
            "\n",
            "[100] Tenopir C, Sandusky RJ and Casado MM. Uses of figures and tables from scholarly journal articles in teaching and research,\n",
            "\n",
            "2007.\n",
            "\n",
            "[101] Hearst MA, Divoli A, Guturu H, Ksikes A, Nakov P, Wooldridge MA et al. BioText Search Engine: Beyond abstract search.\n",
            "\n",
            "Bioinformatics 2007; 23(16): 2196–2197.\n",
            "\n",
            "[102] Mitra CBASaM. Pivoted document length normalization. In: Proceedings of the 19th annual international ACM SIGIR confer-\n",
            "\n",
            "ence on research and development in information retrieval. New York: ACM, p. 21C9.\n",
            "\n",
            "[103] Ponte JM and Croft WB. A language modeling approach to information retrieval. In: Proceedings of 21st annual international\n",
            "ACM SIGIR conference on research and development in information retrieval, Melbourne. New York: ACM, 1998, pp. 275–\n",
            "281.\n",
            "\n",
            "[104] Robertson WE, Walker S and Beaulieu M. Okapi at trecc7: Automatic ad hoc, filtering, vlc and filtering tracks. In: 7th text\n",
            "\n",
            "retrieval conference, TREC7. NIST Special Publications, SP 500-242,1998, p. 253.\n",
            "\n",
            "[105] Brin LPS. The anatomy of a large-scale hypertextual web search engine. In: Proceedings of the seventh international confer-\n",
            "\n",
            "ence on World Wide Web, 1999, pp. 107–117.\n",
            "\n",
            "[106] Varish M (ed.). DC proposal: Graphical models and probabilistic reasoning for generating linked data from tables. In:\n",
            "\n",
            "Proceedings of tenth international Semantic Web conference, Part II, 2011.\n",
            "\n",
            "[107] Ramana C, Jandhyala MK, Nagy G, Padmanabhan R, Seth S and Silversmith W. From tessellations to table interpretation.\n",
            "\n",
            "Berlin: Springer, 2009.\n",
            "\n",
            "[108] Nagy G, Padmanabhan R, Jandhyala RC and Silversmith W. Table metadata: Headers, augmentations and aggregates.\n",
            "\n",
            "DocLab, Rensselaer Polytechnic Institute, Troy, NY, 2010.\n",
            "\n",
            "[109] Tim Finin ZS, Mulwad V and Joshi A. Exploiting a Web of semantic data for interpreting tables. In: Web science conference,\n",
            "\n",
            "2010.\n",
            "\n",
            "[110] Hu J, Kashi RS, Lopresti D and Wilfong GT. Evaluating the performance of table processing algorithms. International\n",
            "\n",
            "Journal on Document Analysis and Recognition 2002; 4(3): 140–153.\n",
            "\n",
            "[111] Phillips I. User’s reference manual for the UW english/technical document image database III. UW-III English/Technical\n",
            "\n",
            "Document Image Database Manual, 1996.\n",
            "\n",
            "[112] Wang Y, Haralick M, Haralick RM and Phillips IT. Document analysis: Table structure understanding and zone content classi-\n",
            "\n",
            "fication, 2002.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "57\n",
            "\n",
            "[113] Wu W, Li H, Wang H and Zhu K. Towards a probabilistic taxonomy of many concepts. Technical Report MSR-TR-2011-25,\n",
            "\n",
            "Microsoft Research, 2011.\n",
            "\n",
            "[114] Suchanek FM, Kasneci G and Weikum G (eds). Yago: A core of semantic knowledge. In: Proceedings of the 16th interna-\n",
            "\n",
            "tional conference on World Wide Web. New York: ACM, 2007.\n",
            "\n",
            "[115] Bizer C, Lehmann J, Kobilarov G, Auer S, Becker C, Cyganiak R et al. DBpedia – A crystallization point for the Web of Data.\n",
            "\n",
            "Web Semantics: Science, Services and Agents on the World Wide Web 2009; 7(3): 154–165.\n",
            "\n",
            "[116] Pitale S and Sharma T. Information Extraction tools for portable document format. International Journal of Computer\n",
            "\n",
            "Technology and Applications 2011; 2(6).\n",
            "\n",
            "[117] Shaker M, Ibrahim H, Mustapha A and Abdullah N. Information extraction from web tables. In: Proceedings of the 11th inter-\n",
            "\n",
            "national conference on information integration and Web-based applications & services, 2009, pp. 470–476.\n",
            "\n",
            "[118] Zwicklbauer S, Einsiedler C, Granitzer M and Seifert C. Towards disambiguating Web tables. ISWC (P&D) 2013; 205–208.\n",
            "[119] Alrashed SA. Finding hidden semantics of text tables. In: Document analysis systems VII. Berlin: Springer, 2006, pp. 449–461.\n",
            "[120] Beel J, Gipp B, Shaker A, and Friedrich N. SciPlore Xtract: Extracting Titles from Scientific PDF Documents by Analyzing\n",
            "Style Information (Font Size). Research and Advanced Technology for Digital Libraries, LNCS 6273 (Springer, Berlin,\n",
            "2010), 413–416.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\f"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLPPRDRmFxmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93480857-bf8b-478f-f5b3-789af55b135c"
      },
      "source": [
        "!pdf2txt.py -o op1.txt -p 1,2 trial.pdf\n",
        "!cat op1.txt"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article\n",
            "\n",
            "On methods and tools of table\n",
            "detection, extraction and annotation in\n",
            "PDF documents\n",
            "\n",
            "Journal of Information Science\n",
            "2015, Vol. 41(1) 41–57\n",
            "Ó The Author(s) 2014\n",
            "Reprints and permissions:\n",
            "sagepub.co.uk/journalsPermissions.nav\n",
            "DOI: 10.1177/0165551514551903\n",
            "jis.sagepub.com\n",
            "\n",
            "Shah Khusro\n",
            "Department of Computer Science, University of Peshawar, Pakistan\n",
            "\n",
            "Asima Latif\n",
            "Department of Computer Science, University of Peshawar, Pakistan\n",
            "\n",
            "Irfan Ullah\n",
            "Department of Computer Science, University of Peshawar, Pakistan\n",
            "\n",
            "Abstract\n",
            "Table detection, extraction and annotation have been an important research problem for years. To handle this issue, different\n",
            "approaches have been designed for different types of documents. Among these PDF is a widely used format for preserving and pre-\n",
            "senting different types of documents. We investigate the state of the art in table detection, extraction and annotation in PDF docu-\n",
            "ments. Because of varying table structural anatomy, the state of the art in table-related research enumerates a number of approaches\n",
            "that are critically and analytically investigated for identifying their strengths and limitations as well as for making recommendations for\n",
            "further improvement. An evaluation framework is contributed that compares different information extraction tools that may be used\n",
            "in table detection, extraction and annotation. We found very limited attention towards these aspects in books, especially books in\n",
            "PDF format. There is no searching solution that can find books having tables that are semantically related to a table in a given book.\n",
            "\n",
            "Keywords\n",
            "Table detection; table extraction; table annotation; semantic table extraction\n",
            "\n",
            "1. Introduction\n",
            "\n",
            "In today’s digital world most information is unstructured, about 80% of it being textual and presented to users in a vari-\n",
            "ety of formats and structures [1]. PDF, which is short for Portable Document Format, is the most common among these.\n",
            "Being portable, PDF allows users to easily view documents and discuss their ideas with each other without taking care\n",
            "of the underlying platform. In PDF documents are presented in a way that is independent of the application software or\n",
            "hardware that was originally used for their production [2]. According to Merz, PDF preserves the structure and layout of\n",
            "a document both on screen as well as during printing. Merz views it as a file format that saves graphically and typogra-\n",
            "phically complex documents [3]. From a reader’s point of view its most exciting properties include platform indepen-\n",
            "dence, portability, compression and font independence (include font descriptor). Being descendent from PostScript (PS)\n",
            "Page Description Programming Language, it avoids programming for the sake of simplicity; however, it creates com-\n",
            "plexities in machine readability. This is because of its layout-oriented format that focuses on human readability, making\n",
            "its further processing difficult to handle. Therefore, the development of complex algorithms is required for text recogni-\n",
            "tion, editing and reinventing structural information. From a PDF developer’s point of view, the exciting characteristics\n",
            "include random access because of cross-referenced table and incremental updates [3].\n",
            "\n",
            "Corresponding author:\n",
            "Shah Khusro, Department of Computer Science, University of Peshawar, Peshawar, 25120, Pakistan.\n",
            "Email: khusro@upesh.edu.pk\n",
            "\n",
            "\fKhusro et al.\n",
            "\n",
            "42\n",
            "\n",
            "Several open-source and proprietary tools are available for information extraction form PDF documents; however,\n",
            "output is not always accurate. There are several elements of a PDF that may produce errors during the conversion process\n",
            "[4], like spaces between words, hyphens, emphasis, superscripting and subscripting, subfonting and special characters.\n",
            "Extracting structural information is also problematic in PDF documents. Examples include multiple columns, paragraph\n",
            "delineation, page headers and footers, tables, graphics and mathematical equations. Among these, tables are the hardest\n",
            "elements to extract. This review paper is a serious attempt towards the state of the art in table detection, extraction, explo-\n",
            "ration and semantic annotation along with different tools and techniques that have been developed and may be used so\n",
            "far for such purposes. The rest of the paper is organized as follows: Section 2 investigates different approaches towards\n",
            "defining tables and highlights the importance of table from different aspects; Section 3 presents an evaluation framework\n",
            "for comparing different open-source and proprietary tools that may be used for table detection, extraction and annotation;\n",
            "Section 4 presents the state of the art in table detection, extraction and annotations; and finally Section 5 concludes our\n",
            "discussion and describes some open issues and recommendations for future work.\n",
            "\n",
            "2. Tables and their importance\n",
            "\n",
            "Tables are important and valuable structures in both printed and digital media and play a vital role in augmenting under-\n",
            "standing of a particular topic, an issue of interest or phenomena. This section presents some definitions of tables that aim\n",
            "to explore their nature and investigates their importance from various aspects.\n",
            "\n",
            "2.1. Defining tables\n",
            "\n",
            "Various approaches exist towards table definition. A table is a representation of a set of relations between organized\n",
            "hierarchical concepts or categories [5]. It is a superstructure in plain text that is imposed on a character-level grid [6]. It\n",
            "comprises a regular and repetitive structure along one dimension in order for data type to be determined using either a\n",
            "horizontal or vertical index [7]. It is an object that uses linear visual clues for simultaneous description of logical con-\n",
            "nections between well-defined and discrete content entries in it where a content entry is the basic entity of information\n",
            "that can be any visual symbol [8]. All of these definitions sound reasonable for describing tables; however, the most ver-\n",
            "ifiable and reliable definition comes from Cameron Silva, in which a table is a graphical grid of a matrix Mi,j, (a) with\n",
            "atomic elements i, j, (b) having linear visual clues such as elements in each row i tend to align horizontally where ele-\n",
            "ments of a column j tend to align vertically and (c) with linear visual clues that depict some logical relationships [9].\n",
            "The question what constitutes a table is indeed still difficult to answer [10].\n",
            "\n",
            "Tables differ significantly in variety, structure, flexibility, notation, representation and use [9]. Normally a table has\n",
            "two forms: raw text tables, generally ASCII text in monospace font, delimited by white space and/or special characters,\n",
            "and rich text tables like those formatted using LaTeX, PDF, HTML and other such formats [11]. Because of these differ-\n",
            "ent representations, no single table processing algorithm works for all mediums. Each algorithm has limitations, and no\n",
            "single algorithm can provide ideal performance considering all evaluation metrics [12].\n",
            "\n",
            "Usually tables are perceived as rectangular structures having rows and columns made up of cells. Inside a table, col-\n",
            "umn and row boundaries are normally recognized as delimiters that are very important for table detection. These delimi-\n",
            "ters are diverse in shape and structure. For example row delimiters may be sequences of punctuation characters, blank\n",
            "lines, new line characters or a mixture of these. Column delimiters may be repeated with white spaces and vertical bar\n",
            "characters. A cell may contain nested tables, other shapes and so on. Simply, a table has diverse structure that depends\n",
            "upon the media hosting it, the need for its creation and the content it contains. The diverse nature, structural irregularities\n",
            "and sometimes missing data make table processing a challenging task [13].\n",
            "\n",
            "2.2. Importance of tables in documents\n",
            "\n",
            "A table is a compact and efficient presentation that is commonly used in various types of documents, especially for\n",
            "describing statistical and relational information [14]. It enables readers to rapidly search, compare and understand facts\n",
            "and draw conclusions [15]. It is viewed as a two-dimensional representation of logical relationships between groups of\n",
            "data [16] where the header row represents the type of data that will be stored in subsequent rows of the table, forming\n",
            "instances of the entity being represented by the table. Thus values stored in a particular row represent some relationship\n",
            "with each other that gives a clue that a huge amount of information can be extracted from table structure. This is an\n",
            "important issue in the field of document layout analysis [13]. Similarly, for many other applications, it is important to\n",
            "understand the structure and content-sharing characteristics of tables. For example, in most research and discovery fields,\n",
            "experimental as well as other factual data are represented as well as explained with the help of tables [17].\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "\f"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuMXSnUxIhet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pdf2txt.py -o op1.html -p 1 -V trial.pdf\n",
        "# !pdf2txt.py -o op1.txt -p 1 -V trial.pdf\n",
        "# !cat op1.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY4lcKLYJept",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser\n",
        "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
        "from pdfminer.pdfinterp import PDFResourceManager\n",
        "from pdfminer.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer.pdfdevice import PDFDevice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Zg3lI3Kygr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open a PDF file.\n",
        "fp = open('trial.pdf', 'rb')\n",
        "# Create a PDF parser object associated with the file object.\n",
        "parser = PDFParser(fp)\n",
        "# Create a PDF document object that stores the document structure.\n",
        "document = PDFDocument(parser)\n",
        "if not document.is_extractable:\n",
        "  raise PDFTextExtractionNotAllowed\n",
        "\n",
        "# Create a PDF resource manager object that stores shared resources.\n",
        "rsrcmgr = PDFResourceManager()\n",
        "# Create a PDF device object.\n",
        "device = PDFDevice(rsrcmgr)\n",
        "# Create a PDF interpreter object.\n",
        "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "for page in PDFPage.create_pages(document):\n",
        "  interpreter.process_page(page)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DDameNnM32E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbab49ba-9ccb-4ee8-b663-339c2f444457"
      },
      "source": [
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.converter import PDFPageAggregator\n",
        "from pdfminer.layout import LTTextBoxHorizontal\n",
        "document = open('trial.pdf', 'rb')\n",
        "#Create resource manager\n",
        "rsrcmgr = PDFResourceManager()\n",
        "# Set parameters for analysis.\n",
        "laparams = LAParams()\n",
        "# Create a PDF page aggregator object.\n",
        "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
        "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "for page in PDFPage.get_pages(document):\n",
        "  interpreter.process_page(page)\n",
        "  # receive the LTPage object for the page.\n",
        "  layout = device.get_result()\n",
        "  for element in layout:\n",
        "    if isinstance(element, LTTextBoxHorizontal):\n",
        "      print(element.get_text())\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "c\n",
            "\n",
            "i\n",
            "\n",
            "/\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "a\n",
            "v\n",
            "e\n",
            "i\n",
            "r\n",
            "t\n",
            "e\n",
            "r\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            ",\n",
            "s\n",
            "h\n",
            "p\n",
            "a\n",
            "r\n",
            "g\n",
            "a\n",
            "r\n",
            "a\n",
            "p\n",
            "\n",
            "e\n",
            "v\n",
            "r\n",
            "e\n",
            "s\n",
            "e\n",
            "r\n",
            "P\n",
            "\n",
            "—\n",
            "\n",
            ".\n",
            "t\n",
            "x\n",
            "e\n",
            "t\n",
            "\n",
            "l\n",
            "\n",
            "n\n",
            "m\n",
            "u\n",
            "o\n",
            "c\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "m\n",
            "t\n",
            "h\n",
            "2\n",
            "d\n",
            "p\n",
            "\n",
            "f\n",
            "\n",
            "n\n",
            "o\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "B\n",
            "\n",
            "/\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "/\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "m\n",
            "t\n",
            "h\n",
            "\n",
            "o\n",
            "t\n",
            "\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "o\n",
            "o\n",
            "t\n",
            "\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "m\n",
            "m\n",
            "o\n",
            "c\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "o\n",
            "t\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "w\n",
            "e\n",
            "v\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "i\n",
            "r\n",
            "p\n",
            "\n",
            ",\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "i\n",
            "d\n",
            "E\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "V,\n",
            "S\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "F\n",
            "T\n",
            "R\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            ".\n",
            "\n",
            "d\n",
            "r\n",
            "o\n",
            "W\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "F\n",
            "T\n",
            "R\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "s\n",
            "e\n",
            "r\n",
            "u\n",
            "t\n",
            "a\n",
            "e\n",
            "F\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "e\n",
            "d\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "e\n",
            "c\n",
            "r\n",
            "u\n",
            "o\n",
            "S\n",
            "\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "u\n",
            "p\n",
            "t\n",
            "u\n",
            "O\n",
            "\n",
            "/\n",
            "t\n",
            "x\n",
            "e\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "/\n",
            "t\n",
            "n\n",
            "o\n",
            "f\n",
            "/\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "a\n",
            "t\n",
            "a\n",
            "d\n",
            "a\n",
            "t\n",
            "e\n",
            "m\n",
            "\n",
            "m\n",
            "r\n",
            "o\n",
            "f\n",
            "t\n",
            "a\n",
            "l\n",
            "P\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "L\n",
            "\n",
            "s\n",
            "l\n",
            "o\n",
            "o\n",
            "T\n",
            "\n",
            "T\n",
            "\n",
            "T\n",
            "\n",
            "I\n",
            "/\n",
            "\n",
            "T\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "I\n",
            "/\n",
            "\n",
            "T\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "/\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "x\n",
            "u\n",
            "n\n",
            "L\n",
            "\n",
            "i\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "l\n",
            "r\n",
            "e\n",
            "P\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "n\n",
            "o\n",
            "h\n",
            "t\n",
            "y\n",
            "p\n",
            "\n",
            "+\n",
            "a\n",
            "+\n",
            "v\n",
            "C\n",
            "a\n",
            "J\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "]\n",
            "0\n",
            "2\n",
            "1\n",
            "[\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "X\n",
            "e\n",
            "r\n",
            "o\n",
            "P\n",
            "c\n",
            "S\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "1\n",
            "e\n",
            "n\n",
            "o\n",
            "t\n",
            "s\n",
            "n\n",
            "e\n",
            "e\n",
            "r\n",
            "G\n",
            "\n",
            "5\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "-\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "-\n",
            "f\n",
            "d\n",
            "p\n",
            "\n",
            "l\n",
            "\n",
            "2\n",
            "x\n",
            "o\n",
            "B\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "3\n",
            "\n",
            "t\n",
            "x\n",
            "e\n",
            "T\n",
            "\n",
            "i\n",
            "\n",
            "f\n",
            "\n",
            "4\n",
            "d\n",
            "P\n",
            "E\n",
            "C\n",
            "\n",
            "I\n",
            "\n",
            "7\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "2\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "6\n",
            "a\n",
            "l\n",
            "u\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "y\n",
            "r\n",
            "e\n",
            "V\n",
            "\n",
            "8\n",
            "r\n",
            "o\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "\n",
            "9\n",
            "o\n",
            "o\n",
            "T\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "n\n",
            "O\n",
            "e\n",
            "b\n",
            "o\n",
            "d\n",
            "A\n",
            "\n",
            "l\n",
            "\n",
            "0\n",
            "1\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "2\n",
            "d\n",
            "P\n",
            "\n",
            "f\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "/\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "l\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "l\n",
            "a\n",
            "d\n",
            "e\n",
            "P\n",
            "\n",
            "J\n",
            "\n",
            ".\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "o\n",
            "n\n",
            "n\n",
            "a\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "e\n",
            "d\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "u\n",
            "\n",
            "e\n",
            "b\n",
            "\n",
            "y\n",
            "a\n",
            "m\n",
            "\n",
            "t\n",
            "a\n",
            "h\n",
            "t\n",
            "\n",
            "s\n",
            "l\n",
            "o\n",
            "o\n",
            "t\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "n\n",
            "\n",
            "f\n",
            "\n",
            "i\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "r\n",
            "a\n",
            "p\n",
            "m\n",
            "o\n",
            "c\n",
            "\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "k\n",
            "r\n",
            "o\n",
            "w\n",
            "e\n",
            "m\n",
            "a\n",
            "r\n",
            "f\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "u\n",
            "l\n",
            "a\n",
            "v\n",
            "E\n",
            "\n",
            ".\n",
            "\n",
            "l\n",
            "\n",
            "1\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "p\n",
            "u\n",
            "s\n",
            "\n",
            ",\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            ",\n",
            "s\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "e\n",
            "r\n",
            "u\n",
            "c\n",
            "e\n",
            "s\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "r\n",
            "i\n",
            "a\n",
            "p\n",
            "e\n",
            "R\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "e\n",
            "d\n",
            "o\n",
            "c\n",
            "n\n",
            "U\n",
            "\n",
            "i\n",
            "\n",
            "M\n",
            "\n",
            "/\n",
            "I\n",
            "/\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "l\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "44\n",
            "\n",
            ")\n",
            "d\n",
            "e\n",
            "u\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "o\n",
            "c\n",
            "(\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "l\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "p\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "m\n",
            "\n",
            "r\n",
            "e\n",
            "h\n",
            "t\n",
            "o\n",
            "\n",
            "h\n",
            "t\n",
            "i\n",
            "\n",
            "w\n",
            "s\n",
            "k\n",
            "r\n",
            "o\n",
            "w\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "n\n",
            "i\n",
            "g\n",
            "n\n",
            "e\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "/\n",
            "e\n",
            "v\n",
            "e\n",
            "i\n",
            "r\n",
            "t\n",
            "e\n",
            "r\n",
            "/\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            "n\n",
            "e\n",
            "p\n",
            "O\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "t\n",
            "u\n",
            "o\n",
            "y\n",
            "a\n",
            "l\n",
            "\n",
            "l\n",
            "a\n",
            "n\n",
            "i\n",
            "g\n",
            "i\n",
            "r\n",
            "o\n",
            "\n",
            "e\n",
            "h\n",
            "t\n",
            "\n",
            "h\n",
            "t\n",
            "i\n",
            "\n",
            "w\n",
            "s\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "d\n",
            "e\n",
            "n\n",
            "i\n",
            "a\n",
            "t\n",
            "e\n",
            "r\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "o\n",
            "o\n",
            "t\n",
            "\n",
            "s\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "k\n",
            "n\n",
            "a\n",
            "r\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "T\n",
            "\n",
            "—\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "—\n",
            "\n",
            "4\n",
            "1\n",
            "0\n",
            "3\n",
            "\n",
            ".\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "Y\n",
            "Y\n",
            "B\n",
            "B\n",
            "A\n",
            "\n",
            "r\n",
            "e\n",
            "m\n",
            "r\n",
            "o\n",
            "f\n",
            "s\n",
            "n\n",
            "a\n",
            "r\n",
            "T\n",
            "\n",
            "]\n",
            "1\n",
            "2\n",
            "[\n",
            "\n",
            "r\n",
            "e\n",
            "e\n",
            "S\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "p\n",
            "y\n",
            "r\n",
            "c\n",
            "n\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "r\n",
            "e\n",
            "v\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "v\n",
            "e\n",
            "\n",
            "l\n",
            "\n",
            "y\n",
            "t\n",
            "i\n",
            "r\n",
            "u\n",
            "c\n",
            "e\n",
            "s\n",
            "\n",
            "t\n",
            "s\n",
            "u\n",
            "d\n",
            "A\n",
            "\n",
            "j\n",
            "\n",
            "s\n",
            "k\n",
            "r\n",
            "a\n",
            "m\n",
            "k\n",
            "o\n",
            "o\n",
            "b\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "k\n",
            "c\n",
            "e\n",
            "h\n",
            "c\n",
            "\n",
            "y\n",
            "c\n",
            "n\n",
            "e\n",
            "t\n",
            "s\n",
            "i\n",
            "s\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "p\n",
            "y\n",
            "r\n",
            "c\n",
            "n\n",
            "e\n",
            "\n",
            ",\n",
            "s\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "s\n",
            "i\n",
            "m\n",
            "r\n",
            "e\n",
            "p\n",
            "\n",
            ",\n",
            "s\n",
            "d\n",
            "r\n",
            "o\n",
            "w\n",
            "s\n",
            "s\n",
            "a\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "/\n",
            "c\n",
            "o\n",
            "d\n",
            "/\n",
            "t\n",
            "x\n",
            "e\n",
            "T\n",
            "\n",
            "e\n",
            "d\n",
            "o\n",
            "c\n",
            "n\n",
            "U\n",
            "\n",
            "i\n",
            "\n",
            "M\n",
            "\n",
            "/\n",
            "I\n",
            "/\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            ",\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            ",\n",
            "\n",
            "S\n",
            "P\n",
            "X\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "F,\n",
            "T\n",
            "R\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "T\n",
            "\n",
            "-\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "x\n",
            "u\n",
            "n\n",
            "L\n",
            "\n",
            "i\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "+\n",
            "+\n",
            "C\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "t\n",
            "e\n",
            "N\n",
            "\n",
            ".\n",
            "\n",
            ",\n",
            "a\n",
            "v\n",
            "a\n",
            "J\n",
            "\n",
            "1\n",
            "1\n",
            "r\n",
            "e\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            "d\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "o\n",
            "S\n",
            "\n",
            "y\n",
            "b\n",
            "\n",
            "r\n",
            "e\n",
            "z\n",
            "y\n",
            "l\n",
            "a\n",
            "n\n",
            "A\n",
            "-\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "y\n",
            "b\n",
            "\n",
            "r\n",
            "e\n",
            "z\n",
            "y\n",
            "l\n",
            "a\n",
            "n\n",
            "A\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "]\n",
            "9\n",
            "1\n",
            "[\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "k\n",
            "e\n",
            "o\n",
            "m\n",
            "h\n",
            "c\n",
            "S\n",
            "\n",
            "i\n",
            "\n",
            "n\n",
            "u\n",
            "y\n",
            "m\n",
            "A\n",
            "\n",
            "]\n",
            "0\n",
            "2\n",
            "[\n",
            "s\n",
            "e\n",
            "i\n",
            "g\n",
            "o\n",
            "o\n",
            "n\n",
            "h\n",
            "c\n",
            "e\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            "3\n",
            "1\n",
            "T\n",
            "E\n",
            "T\n",
            "b\n",
            "L\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "s\n",
            "t\n",
            "h\n",
            "g\n",
            "i\n",
            "e\n",
            "H\n",
            "-\n",
            "3\n",
            "\n",
            "2\n",
            "1\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "45\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            ",\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "\n",
            "l\n",
            "l\n",
            "\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "w\n",
            "e\n",
            "v\n",
            "\n",
            "i\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "s\n",
            "e\n",
            "v\n",
            "o\n",
            "m\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "p\n",
            "u\n",
            "s\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "i\n",
            "r\n",
            "p\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            ",\n",
            "s\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "e\n",
            "t\n",
            "o\n",
            "u\n",
            "q\n",
            "\n",
            "y\n",
            "\n",
            "l\n",
            "i\n",
            "s\n",
            "a\n",
            "e\n",
            "\n",
            "i\n",
            "\n",
            ",\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "S\n",
            "\n",
            "s\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "e\n",
            "v\n",
            "o\n",
            "r\n",
            "p\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "o\n",
            "n\n",
            "n\n",
            "a\n",
            "\n",
            "g\n",
            "n\n",
            "i\n",
            "s\n",
            "s\n",
            "e\n",
            "c\n",
            "o\n",
            "r\n",
            "p\n",
            "\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "\n",
            "m\n",
            "a\n",
            "e\n",
            "r\n",
            "t\n",
            "s\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "—\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "o\n",
            "n\n",
            "n\n",
            "a\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "c\n",
            "i\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "c\n",
            "\n",
            "i\n",
            "\n",
            "/\n",
            "g\n",
            "n\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            "l\n",
            "a\n",
            "v\n",
            "e\n",
            "i\n",
            "r\n",
            "t\n",
            "e\n",
            "r\n",
            "\n",
            "s\n",
            "e\n",
            "r\n",
            "u\n",
            "t\n",
            "a\n",
            "e\n",
            "F\n",
            "\n",
            "/\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "e\n",
            "d\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "e\n",
            "c\n",
            "r\n",
            "u\n",
            "o\n",
            "S\n",
            "\n",
            "t\n",
            "a\n",
            "m\n",
            "r\n",
            "o\n",
            "\n",
            "f\n",
            "\n",
            "t\n",
            "u\n",
            "p\n",
            "t\n",
            "u\n",
            "O\n",
            "\n",
            "/\n",
            "t\n",
            "x\n",
            "e\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "/\n",
            "t\n",
            "n\n",
            "o\n",
            "f\n",
            "/\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "i\n",
            "\n",
            "a\n",
            "t\n",
            "a\n",
            "d\n",
            "a\n",
            "t\n",
            "e\n",
            "m\n",
            "\n",
            "m\n",
            "r\n",
            "o\n",
            "f\n",
            "t\n",
            "a\n",
            "l\n",
            "P\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "u\n",
            "g\n",
            "n\n",
            "a\n",
            "L\n",
            "\n",
            "s\n",
            "l\n",
            "o\n",
            "o\n",
            "T\n",
            "\n",
            ")\n",
            "d\n",
            "e\n",
            "u\n",
            "n\n",
            "i\n",
            "t\n",
            "n\n",
            "o\n",
            "c\n",
            "(\n",
            "\n",
            ".\n",
            "\n",
            "1\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "t\n",
            "c\n",
            "e\n",
            "t\n",
            "o\n",
            "r\n",
            "p\n",
            "\n",
            ",\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "x\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "e\n",
            "r\n",
            "c\n",
            "\n",
            ",\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "s\n",
            "u\n",
            "\n",
            "o\n",
            "t\n",
            "\n",
            "s\n",
            "e\n",
            "\n",
            "l\n",
            "i\n",
            "f\n",
            "\n",
            "y\n",
            "s\n",
            "a\n",
            "E\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "F,\n",
            "T\n",
            "R\n",
            "\n",
            ",\n",
            "\n",
            "c\n",
            "o\n",
            "D\n",
            "\n",
            "I\n",
            "/\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "d\n",
            "u\n",
            "o\n",
            "c\n",
            "\n",
            "l\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "r\n",
            "o\n",
            "b\n",
            "a\n",
            "l\n",
            "l\n",
            "\n",
            "o\n",
            "c\n",
            "\n",
            ",\n",
            "s\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "e\n",
            "r\n",
            "u\n",
            "c\n",
            "e\n",
            "s\n",
            "\n",
            "y\n",
            "t\n",
            "i\n",
            "v\n",
            "i\n",
            "t\n",
            "c\n",
            "e\n",
            "n\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "\n",
            ",\n",
            "t\n",
            "r\n",
            "o\n",
            "p\n",
            "p\n",
            "u\n",
            "s\n",
            "A\n",
            "/\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "c\n",
            "a\n",
            "f\n",
            "r\n",
            "e\n",
            "t\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "x\n",
            "e\n",
            "p\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "L\n",
            "M\n",
            "X\n",
            "\n",
            "-\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            ",\n",
            "t\n",
            "r\n",
            "e\n",
            "v\n",
            "n\n",
            "o\n",
            "c\n",
            "\n",
            ",\n",
            "t\n",
            "i\n",
            "d\n",
            "e\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "e\n",
            "r\n",
            "c\n",
            "\n",
            ",\n",
            "\n",
            "e\n",
            "c\n",
            "a\n",
            "f\n",
            "r\n",
            "e\n",
            "t\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "p\n",
            "m\n",
            "S\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            "c\n",
            "o\n",
            "d\n",
            "/\n",
            "l\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            "F\n",
            "/\n",
            "I\n",
            "/\n",
            "\n",
            "T\n",
            "\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "l\n",
            "\n",
            "s\n",
            "e\n",
            "b\n",
            "a\n",
            "t\n",
            "\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "E\n",
            "\n",
            "l\n",
            "a\n",
            "i\n",
            "c\n",
            "r\n",
            "e\n",
            "m\n",
            "m\n",
            "o\n",
            "C\n",
            "\n",
            ",\n",
            "l\n",
            "\n",
            "e\n",
            "c\n",
            "x\n",
            "E\n",
            "\n",
            ",\n",
            "\n",
            "c\n",
            "o\n",
            "d\n",
            "\n",
            "F,\n",
            "T\n",
            "R\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "d\n",
            "n\n",
            "a\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "F\n",
            "/\n",
            "T\n",
            "\n",
            "/\n",
            "I\n",
            "\n",
            "/\n",
            "s\n",
            "w\n",
            "o\n",
            "d\n",
            "n\n",
            "\n",
            "i\n",
            "\n",
            "W\n",
            "\n",
            "c\n",
            "a\n",
            "M\n",
            "\n",
            "i\n",
            "t\n",
            "l\n",
            "u\n",
            "M\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "5\n",
            "1\n",
            "r\n",
            "e\n",
            "d\n",
            "a\n",
            "e\n",
            "r\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            "r\n",
            "a\n",
            "l\n",
            "u\n",
            "k\n",
            "O\n",
            "\n",
            "r\n",
            "e\n",
            "d\n",
            "a\n",
            "e\n",
            "R\n",
            "e\n",
            "n\n",
            "F\n",
            "Y\n",
            "Y\n",
            "B\n",
            "B\n",
            "A\n",
            "\n",
            "i\n",
            "\n",
            "I\n",
            "\n",
            "X\n",
            "\n",
            "t\n",
            "a\n",
            "b\n",
            "o\n",
            "r\n",
            "c\n",
            "A\n",
            "e\n",
            "b\n",
            "o\n",
            "d\n",
            "A\n",
            "\n",
            "7\n",
            "1\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "e\n",
            "t\n",
            "a\n",
            "r\n",
            "o\n",
            "p\n",
            "r\n",
            "o\n",
            "C\n",
            "0\n",
            "1\n",
            "1\n",
            "\n",
            ".\n",
            "\n",
            "6\n",
            "1\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "i\n",
            "d\n",
            "E\n",
            "\n",
            "8\n",
            "1\n",
            "\n",
            "i\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "P\n",
            "n\n",
            "m\n",
            "O\n",
            "\n",
            "l\n",
            "a\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "s\n",
            "e\n",
            "f\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "8\n",
            "1\n",
            "\n",
            "9\n",
            "1\n",
            "8\n",
            "\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "o\n",
            "r\n",
            "t\n",
            "i\n",
            "\n",
            "N\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "46\n",
            "\n",
            "tables, no tool is perfect in extracting all sorts of tables. TableSeer is the only available tool that not only identifies tables\n",
            "but also provides table search and ranking facilities; however, its performance is compromised for complex tables.\n",
            "\n",
            "After reviewing all PDF table-related tools, we find not even a single open-source or proprietary tool that can extract\n",
            "and annotate PDF tables. Therefore, the intense need today is for a PDF table extraction and annotation tool that can\n",
            "extract tables from PDF document with good accuracy and annotate them using surrounding text or using external\n",
            "sources.\n",
            "\n",
            "4. State of the art in table detection, extraction and annotation\n",
            "\n",
            "A detailed bibliography on table segmentation and extraction can be found on visionbib website.20 Much research and\n",
            "development has been carried out on extracting tables from documents and web pages [5, 22], but owing to diversity in\n",
            "table layouts, no work is perfect in extracting all types of tables. Some commonly used words in table processing are\n",
            "detection, extraction [9, 23], interpretation [9] and understanding [24]. Similarly relatively little work has been done\n",
            "focusing semantics extraction from tables and almost no work has been done on extracting, interpreting and semantically\n",
            "annotating book tables for finding/ranking related tables in other books. Only Fang et al. [25] evaluate their table extrac-\n",
            "tion algorithm on an e-book dataset and a scientific document dataset. Their algorithm is integrated into a commercial\n",
            "software package for large-scale Chinese e-book production. Quite simplistic and out-dated surveys about table detection\n",
            "approaches have been contributed by Zanibbi et al. [26] and Silva et al. [9]. This work, however, investigates the state of\n",
            "the art in this area and identifies the underlying problems in these different techniques. The paper investigates research\n",
            "efforts as well as some unsolved key issues. We have also contributed an evaluation framework for comparing PDF\n",
            "extraction tools and assessed their quality for table extraction and annotation. The paper makes some useful recommen-\n",
            "dations about techniques and their usability in the case of tables.\n",
            "\n",
            "The research on tables can be divided into two categories, namely Table Extraction and Table Annotation. The pur-\n",
            "\n",
            "pose of this section is to present the state of the art in table detection, extraction and retrieval.\n",
            "\n",
            "4.1. Table detection in PDF documents\n",
            "\n",
            "PDF is a higher-level document representation format [25] where detecting tables from such documents remains disre-\n",
            "garded by researchers. Therefore, very little work has been carried out on such formats [21, 48, 58, 60]. The most valu-\n",
            "able work regarding table detection from PDF document is TableSeer, which utilizes PDF2TET, PDFBox and Text\n",
            "Extraction Toolkit (TET). The initial step before table extraction from any document is table recognition. In table recog-\n",
            "nition Zanibbi uses table location and composition (a table model) for recovering tables from encoded documents. In this\n",
            "approach, table anatomy consists of column, row, cell, block, headers, body and associated text regions [26].\n",
            "\n",
            "4.1.1. Table detection methodologies. There are three major categories of table detection methodologies: predefined layout\n",
            "approaches [37], heuristics-based approaches [31, 32, 54, 89] and statistical approaches, as well as a mixture of both\n",
            "heuristic and statistical approaches [14]. Shamilian presents a predefine layout based table identification and segmenta-\n",
            "tion algorithm [37]. Their contribution is the provision of graphical user interface for defining new layouts. The problem\n",
            "with their approach is the automatic control of the incoming document format. Also the approach works well only with\n",
            "single-column documents. Another predefined layout based approach is Mohemad et al. [50], which presents a typical\n",
            "work based on a predefined table layout structure for text, then associates text using a combination of heuristics-based,\n",
            "rule-based and predefined layout approaches. This approach shows good performance for tender documents, but being\n",
            "layout dependent, it cannot show good performance in general. Heuristics-based techniques remain dominant in litera-\n",
            "ture, as shown in Table 2. Kieninger [32] relies on complex heuristics that are based on local analysis for table segmen-\n",
            "tation. Some research works used heuristics-based techniques for table detection [23, 27, 29, 31, 33, 36, 38, 41, 42,\n",
            "48, 52–61]. Interested readers may consult them for further details. Few research works pay attention to the use of statis-\n",
            "tical approaches for table detection, including probabilistic modelling [40], the Naive Bayes classifier [44, 52, 57, 61,\n",
            "66], the Maximum Entropy Classifier [34, 44], decision trees [40, 44, 45, 68], Support Vector Machine [45, 51, 59, 65],\n",
            "the Winnow classifier [44], Conditional Random Fields [33, 34, 51, 59, 67] and an HMM of the traditional sort [70].\n",
            "Mostly these have been applied as off-the-shelf techniques with no investigation as to how they can be optimized for\n",
            "document analysis problems. Oro and Ruffolo [60] use a mixture of both heuristics and statistics. Wang and Hu [45] use\n",
            "both Decision Tree Classifier and SVM for finding fake and genuine entities. For this they utilize table layout and con-\n",
            "tent type and word groups as a base. Conditional Random Fields have been introduced by Lafferty et al. [65] for\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "47\n",
            "\n",
            "]\n",
            "7\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "6\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "6\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "8\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "8\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "4\n",
            "6\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "3\n",
            "6\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "\n",
            "]\n",
            "4\n",
            "1\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "3\n",
            "3\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "4\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "4\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "4\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "–\n",
            "3\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "8\n",
            "8\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "8\n",
            "[\n",
            "\n",
            "]\n",
            "4\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "6\n",
            "8\n",
            "–\n",
            "5\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "S\n",
            "L\n",
            "X\n",
            "\n",
            "I\n",
            "I\n",
            "\n",
            "C\n",
            "S\n",
            "A\n",
            "\n",
            "L\n",
            "M\n",
            "T\n",
            "H\n",
            "\n",
            "]\n",
            "0\n",
            "5\n",
            "–\n",
            "8\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "4\n",
            "\n",
            "]\n",
            "2\n",
            "4\n",
            "\n",
            "]\n",
            "1\n",
            "6\n",
            "–\n",
            "6\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "4\n",
            "\n",
            "]\n",
            "2\n",
            "5\n",
            "\n",
            "F\n",
            "D\n",
            "P\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "4\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "2\n",
            "[\n",
            "\n",
            "]\n",
            "1\n",
            "5\n",
            "[\n",
            "\n",
            "]\n",
            "0\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "1\n",
            "6\n",
            "–\n",
            "9\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "0\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "9\n",
            "[\n",
            "\n",
            "]\n",
            "9\n",
            "5\n",
            "\n",
            "]\n",
            "9\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "5\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "1\n",
            "6\n",
            "\n",
            "]\n",
            "4\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "5\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "4\n",
            "[\n",
            "\n",
            "]\n",
            "3\n",
            "7\n",
            "–\n",
            "1\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "1\n",
            "[\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "–\n",
            "5\n",
            "3\n",
            "\n",
            "]\n",
            "0\n",
            "4\n",
            "\n",
            ",\n",
            "\n",
            "6\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "3\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "3\n",
            "[\n",
            "\n",
            "e\n",
            "g\n",
            "a\n",
            "m\n",
            "\n",
            "I\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            "]\n",
            "5\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "8\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "6\n",
            "3\n",
            "[\n",
            "\n",
            "]\n",
            "3\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "1\n",
            "3\n",
            "\n",
            "]\n",
            "7\n",
            "6\n",
            "–\n",
            "5\n",
            "6\n",
            "\n",
            "g\n",
            "n\n",
            "\n",
            "i\n",
            "l\n",
            "l\n",
            "\n",
            "e\n",
            "d\n",
            "o\n",
            "M\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "l\n",
            "i\n",
            "\n",
            "b\n",
            "a\n",
            "b\n",
            "o\n",
            "r\n",
            "P\n",
            "\n",
            "]\n",
            "7\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "3\n",
            "[\n",
            "\n",
            "m\n",
            "o\n",
            "d\n",
            "n\n",
            "a\n",
            "R\n",
            "\n",
            "l\n",
            "a\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "i\n",
            "d\n",
            "n\n",
            "o\n",
            "C\n",
            "\n",
            "l\n",
            "\n",
            "d\n",
            "e\n",
            "i\n",
            "f\n",
            "\n",
            "]\n",
            "4\n",
            "3\n",
            "–\n",
            "7\n",
            "2\n",
            "\n",
            "]\n",
            "3\n",
            "3\n",
            "\n",
            ",\n",
            "\n",
            "9\n",
            "2\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "2\n",
            "\n",
            ",\n",
            "\n",
            "4\n",
            "3\n",
            "\n",
            "t\n",
            "x\n",
            "e\n",
            "T\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "3\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "—\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "7\n",
            "2\n",
            "[\n",
            "\n",
            "]\n",
            "5\n",
            "6\n",
            "[\n",
            "\n",
            "—\n",
            "\n",
            "l\n",
            "a\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "S\n",
            "\n",
            "M\n",
            "V\n",
            "S\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "b\n",
            "\n",
            "r\n",
            "e\n",
            "p\n",
            "p\n",
            "a\n",
            "r\n",
            "\n",
            "W\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "b\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "u\n",
            "R\n",
            "\n",
            "t\n",
            "u\n",
            "o\n",
            "y\n",
            "a\n",
            "l\n",
            "\n",
            "d\n",
            "e\n",
            "n\n",
            "\n",
            "i\n",
            "f\n",
            "e\n",
            "d\n",
            "e\n",
            "r\n",
            "P\n",
            "\n",
            "d\n",
            "e\n",
            "s\n",
            "a\n",
            "b\n",
            "\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "r\n",
            "u\n",
            "e\n",
            "H\n",
            "\n",
            "l\n",
            "a\n",
            "c\n",
            "i\n",
            "t\n",
            "s\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "S\n",
            "\n",
            "s\n",
            "e\n",
            "h\n",
            "c\n",
            "a\n",
            "o\n",
            "r\n",
            "p\n",
            "p\n",
            "A\n",
            "\n",
            "—\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "g\n",
            "e\n",
            "S\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "g\n",
            "e\n",
            "S\n",
            "\n",
            "e\n",
            "p\n",
            "y\n",
            "t\n",
            "\n",
            "t\n",
            "n\n",
            "e\n",
            "m\n",
            "u\n",
            "c\n",
            "o\n",
            "D\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "a\n",
            "c\n",
            "o\n",
            "L\n",
            "\n",
            ".\n",
            "\n",
            "h\n",
            "c\n",
            "r\n",
            "a\n",
            "e\n",
            "s\n",
            "e\n",
            "r\n",
            "\n",
            "d\n",
            "e\n",
            "t\n",
            "a\n",
            "l\n",
            "e\n",
            "r\n",
            "-\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "l\n",
            "\n",
            ".\n",
            "\n",
            "l\n",
            "\n",
            "2\n",
            "e\n",
            "b\n",
            "a\n",
            "T\n",
            "\n",
            "]\n",
            "0\n",
            "7\n",
            "\n",
            ",\n",
            "\n",
            "9\n",
            "6\n",
            "\n",
            "]\n",
            "8\n",
            "6\n",
            "\n",
            ",\n",
            "\n",
            "2\n",
            "5\n",
            "\n",
            ",\n",
            "\n",
            "5\n",
            "4\n",
            "[\n",
            "\n",
            ",\n",
            "\n",
            "3\n",
            "2\n",
            "[\n",
            "\n",
            "r\n",
            "e\n",
            "i\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "C\n",
            "s\n",
            "e\n",
            "y\n",
            "a\n",
            "B\n",
            "\n",
            "e\n",
            "v\n",
            "i\n",
            "a\n",
            "N\n",
            "\n",
            "s\n",
            "e\n",
            "e\n",
            "r\n",
            "t\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "s\n",
            "i\n",
            "c\n",
            "e\n",
            "D\n",
            "\n",
            "]\n",
            "4\n",
            "3\n",
            "[\n",
            "\n",
            "y\n",
            "p\n",
            "o\n",
            "r\n",
            "t\n",
            "n\n",
            "E\n",
            "m\n",
            "u\n",
            "m\n",
            "x\n",
            "a\n",
            "M\n",
            "\n",
            "i\n",
            "\n",
            "]\n",
            "4\n",
            "3\n",
            "[\n",
            "\n",
            "l\n",
            "\n",
            "e\n",
            "d\n",
            "o\n",
            "m\n",
            "v\n",
            "o\n",
            "k\n",
            "r\n",
            "a\n",
            "M\n",
            "n\n",
            "e\n",
            "d\n",
            "d\n",
            "H\n",
            "\n",
            "i\n",
            "\n",
            "r\n",
            "e\n",
            "i\n",
            "f\n",
            "i\n",
            "s\n",
            "s\n",
            "a\n",
            "l\n",
            "c\n",
            "\n",
            "n\n",
            "o\n",
            "i\n",
            "t\n",
            "c\n",
            "a\n",
            "r\n",
            "t\n",
            "x\n",
            "e\n",
            "\n",
            "c\n",
            "i\n",
            "t\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "S\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "48\n",
            "\n",
            "segment and label sequence data. Conditional Random Fields are used for part-of-speech tagging [65], shallow parsing\n",
            "[90] and named entity recognition [91] as well as for table detection [34].\n",
            "\n",
            "4.1.2. Tactics used in table detection. Different tactics are used for table detection, namely segmentation-based, rule-based\n",
            "and wrapper-based approaches. The segmentation-based approach is the assignment of physical description to the table\n",
            "by finding its cells, rows, columns and their positions [9]. PDF-TREX is based on segments in lines such as text lines,\n",
            "table lines and unknown lines. This technique works with single-column documents only. Considering white space dis-\n",
            "tributions inside text elements, it calculates horizontal and vertical threshold values based on smallest distance measure\n",
            "between text elements and the last cluster of identical text elements [60]. The contribution of technique is the identifica-\n",
            "tion of spanning columns and empty cells as well as the publication of a freely available dataset. Limitations of this tech-\n",
            "nique include the use of a predefined threshold for calculating distance between text elements as this can produce wrong\n",
            "results because of wrong clusters owing to the combination of dissimilar text parts [50]. The approaches of pdf2table,\n",
            "TableSeer and PDF-TREX Table Lines may have more than one text segment. According to Fang et al., this consider-\n",
            "ation may lead to under- or over-segmentation because it depends on predefined thresholds, spanning cells, and it would\n",
            "be difficult to distinguish between tables if a page contains more than one table. This approach cannot handle sparse\n",
            "tables in a well-mannered way. Border lines and rules play an important role in complex table layouts [25]. These are\n",
            "ignored in all approaches except those of Hassan and Baumgartner [58] and Fang et al. [25] for spotting text regions.\n",
            "\n",
            "The rules-based systems use logical inference for table detection. Mohemad et al. [50] propose a rules-based approach\n",
            "for measuring smallest distance between text chunks in order to minimize wrong cluster creation. They arrange recog-\n",
            "nized text and structure from PDF documents into ontology to assist the further reasoning process, as in Oro E and\n",
            "Ruffolo [60, 61]. However, JPEDAL is used for PDF document coordinate extraction. For result evaluation, the standard\n",
            "information extraction method of precision (PM), recall (RM) and F-measure has been applied. The technique is layout-\n",
            "based and cannot perform well for complex tables.\n",
            "\n",
            "Wrapper-based table detection is a subgraph of the document with some constraints using data instances for extract-\n",
            "ing related data [92]. Hassan and Baumgartner offer a wrapper-based approach for table detection in PDF documents\n",
            "but this method makes use of border lines, rules and text content separately. However, this approach does not verify gra-\n",
            "phic lines first, which produces false-positive lines resulting in false-positive tables [58]. To solve this limitation, Fang\n",
            "et al. propose a table detection method that makes use of both visual separators such as graphics lines and white spaces\n",
            "for unruled tables and irregular tables, for example, sparse tables, nested tables, tables wrapped in body paragraphs and\n",
            "minimizes false-positive table detection. Multicolumn pages are also handled for table detection. In contrast to Hassan\n",
            "and Baumgartner’s technique [58], here table spotting is done after verification of both candidate table content and\n",
            "visual separators, thus resulting in high accuracy. In other words, performance evaluation is needed in order to compare\n",
            "and select the best-suited method for a given application [25].\n",
            "\n",
            "4.2. Table representation approaches\n",
            "\n",
            "Different methods and techniques have been devised for table representation. Here by table representation we mean the\n",
            "formal manipulation of tables without any real understanding of their content [93]. Wang’s model is considered as the\n",
            "most common table model in literature for generating table images from logical structure descriptions, but the model does\n",
            "not describe footnotes or other text associated with a table (e.g. titles or captions). It is also unable to handle nested tables.\n",
            "The model assumes that stub-heads are empty, and headers are only positioned inside the box-head and stub of the table\n",
            "[71]. Similarly, Embley et al. propose a table detection model for web pages that uses domain-specific ontology for table\n",
            "recognition [93]. They admit the usability of Wang model for some table-specific tasks. Their contribution suggests some\n",
            "standard components for any table ontology. Amano and Asada propose a more versatile graph representation scheme for\n",
            "showing cell relationships of a table from documents. The graph is encoded in XML format using context-free grammar\n",
            "for table layouts [94]. Wang uses table ground truth and develops a tool for generating table element-containing docu-\n",
            "ments [95]. All these models cannot cover table-related information as well as document background information [21].\n",
            "\n",
            "Yildiz et al. carried out the first relative research on PDF for tables [48]. This technique uses a pdf2hmtl tool that\n",
            "returns text pieces and their absolute coordinates which are then utilized for table detection and decomposition. The tech-\n",
            "nique is heuristics-based and merges text elements defining single-line, multiline objects and multiline blocks. Finally,\n",
            "detected multiline blocks that may belong to the same table are merged [48]. The technique is limited as it assumes all\n",
            "pages to be single column. The assumptions that the table row contains more than one text segment may lead to under-\n",
            "or over-segmentation of tables. Sparse tables may lead to wrong results. Hurst presents a model that uses segmentation\n",
            "process for identifying PDF document parts [96]. The model also deals with table semantics as well [5]. TableSeer\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "49\n",
            "\n",
            "provides a universal metadata specification for tables for any document medium. Their ongoing task is to incorporate\n",
            "table data with Dublin Core to improve its searching process.\n",
            "\n",
            "4.3. Table classification approaches\n",
            "\n",
            "Table analysis after table extraction has been considered by some researchers [40, 43, 97–99]. Genuine tables have rela-\n",
            "tionships among cells in a two-dimensional grid and non-genuine tables are just clusters for viewing purposes only [45].\n",
            "Similarly, a classification data-table has correlation in cells and layout tables have no correlation, being are just for view-\n",
            "ing purposes only [108]. Hurst classifies tables into two classes where type 1 table implicit relationships are clear in the\n",
            "html document and type 2 tables are for data viewing only [96]. According to Pivk et al. [98], tables are of three layouts:\n",
            "one-dimensional, two-dimensional and complex tables. A one-dimensional table has at least one row of attribute cells\n",
            "above the rows of instance cells. A two-dimensional table has a rectangular area of instance cells appearing within col-\n",
            "umns. Complex tables might have features including partition data labels, over-expanded labels or a combination of these\n",
            "two. Yoshida et al. categorize tables into nine types according to table structure and their relative locations of attribute\n",
            "strings and value strings [99]. For more details about types the interested user may read [99].\n",
            "\n",
            "4.4. Search engines and tables\n",
            "\n",
            "Search engines are used for a variety of purposes including searching images, maps, videos, patents and document parts.\n",
            "Although table-related research has attained tremendous attention, table search has not grown enough. Pyreddy and\n",
            "Croft designed a character alignment graph (CAG) for TINTIN system to extract tables for information retrieval using a\n",
            "question-answering technique. This system indexes and searches tables [27]. Wang and Hu propose a system for storing\n",
            "extracted table data in databases for retrieving information through spoken language interface [45]. According to Wang\n",
            "and Hu, genuine tables are two-dimensional grids expressing logical relationships among cells. However, none of above-\n",
            "mentioned research works provide real table search. Recently, several online systems, including Illustrara [100] and\n",
            "BioText [101] perform searching, but tables are not treated very well, for example, it extracts a single table from a docu-\n",
            "ment and displays it multiple times instead of showing all page tables. Only TableSeer is a table search engine that can\n",
            "retrieve tables in response to user queries and supports automatic table metadata extraction.\n",
            "\n",
            "Obtaining the most relevant results among retrieved results is the most important issue that has been the focus of\n",
            "many researchers and contributors. This is the case where ranking comes forwards. Ranking results are normally based\n",
            "on query/page similarities, various retrieval models such as Vector Space Model with pivoted document length normali-\n",
            "zation [102], language modelling [103], Okapi BM formula [104] and ranking algorithms such as PageRank [105]. The\n",
            "information retrieval models and ranking algorithms provide unwanted and false-positive results in the case of table\n",
            "searching because these cannot recognize the importance of table terms and ignore term locations, table reference text,\n",
            "document quality, etc. [17]. TableSeer [51] also uses a ranking algorithm that extracts tables from documents using a\n",
            "box-cutting method [17] and applies this ranking algorithm on tables. It displays ranked results ordered by date, rele-\n",
            "vance and citation. The approach is limited because of low precision owing to the assumption that all tables have cap-\n",
            "tions. Thus tables having no caption are ignored by the search engines, which could lead to low recall. There are other\n",
            "related tasks such as table compression, table clustering and table margining; however, we do not consider them as they\n",
            "are beyond the scope of this paper.\n",
            "\n",
            "4.5. Datasets and metrics for evaluating table detection algorithms\n",
            "\n",
            "The evaluation of table detection algorithms is a big problem owing to the lack of standard datasets. There is no bench-\n",
            "mark/ground truth to evaluate experimental results; therefore no performance metrics could be achieved [12]. Precision\n",
            "and recall are commonly used as evaluation methods, but are not sufficient for handling all sorts of table detection errors.\n",
            "Luckily researchers have proposed some other evaluation methods for table detection in order to handle errors other than\n",
            "false-positive and false-negative detection. Hu et al. address an edit-distance-based measurement [110]. Shahab et al.\n",
            "propose a colour-encoding-based evaluation method [73]. Silva suggests absolute metrics completeness (proportion of\n",
            "completely identified terms of the total number of original terms) and purity (proportion of pure detected elements of all\n",
            "detected elements) used in ICDAR 2011 (table recognition competition) as performance metrics [68]. All evaluation\n",
            "methods discussed above can evaluate algorithms as a whole and cannot highlight detailed error descriptions with no\n",
            "improvement hints [12].\n",
            "\n",
            "Hu et al. collected 26 Wall Street Journal articles and email messages as a dataset [110]. The Silva dataset is com-\n",
            "posed of 22 PDF financial statements [73]. The UW-III dataset consists of 215 marked table zones in 110 pages. The\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "50\n",
            "\n",
            "dataset is commonly used but, except for bounding box information of the table region, no other structure information is\n",
            "provided [111]. Wang et al. provide a downloadable software tool package, and produced 1125 document image ground-\n",
            "truths, 565 table entities and 10,298 cell entities, but their dataset and ground-truth are not publicly available [14]. Fang\n",
            "et al. [12] provide a ground-truth general dataset, and propose evaluation metrics with publicly available source code for\n",
            "table detection algorithms. They define six general error types: fake, reduced, amplified, splitted, merged and missed.\n",
            "They evaluate three important table detection algorithms, namely TableSeer, pdf2table and their own algorithm [25].\n",
            "\n",
            "4.6. Table extraction and semantic annotation\n",
            "\n",
            "Table interpretation can be considered as finding missing information from the document itself or from external sources\n",
            "[96]. Table semantics extraction has become a dominant field of research. Hurst identifies categories and relationships.\n",
            "For category identification he joins the cells of the same category together and then identifies relationships among cells.\n",
            "He proposes several relationships such as nominal super-type, qualitative super-type, partitive, units of measurement and\n",
            "quantitative. He proposes classification of relationships based on semantic types of the content (dates, numbers, units of\n",
            "measure, years) as well as on the comparison of table content with rest of text in the document and the presence of cer-\n",
            "tain keywords [96].\n",
            "\n",
            "Ferguson worked on category and relation identification in tables and mapped values to ontology, comparing these\n",
            "values with surrounding text. However, this effort is context-dependent and cannot be used out of context [41]. Another\n",
            "approach is the identification of partitive relationships between the content of cells. With these, a hierarchical tree can be\n",
            "built based on table attributes. This tree is then compared word by word with a manually built collection of all possible\n",
            "alternatives to name the concepts they wish to extract [23]. Context ontology can also be used for matching table content\n",
            "with ontology for finding functionality of content in a table, which after structural analysis can be used in table interpreta-\n",
            "tion [112]. Similarly, TANGO [72], short for Table ANalysis for Generating Ontologies, works mostly within the geopo-\n",
            "litical domain. The aim is to semi-automatically generate ontologies for user-chosen domain using software tools as well\n",
            "as user direction and correction. For this purpose, users utilize domain concept-related tables, thus raw tables become\n",
            "interpreted tables.\n",
            "\n",
            "Tijerino et al. present a more detailed description (without experimentation) of their vision of how TANGO should\n",
            "work to automatically generate Semantic Web ontologies from either lists or tables [72]. Embley et al. match table data\n",
            "against their self-created context ontology. This mapping can be direct; merging or splitting of the column’s content may\n",
            "be required. They claim that by changing the context ontology they can adapt to any context [62]. Jha and Nagy did not\n",
            "make use of ontologies; rather they developed a tool based on user involvement for finding categories and relationships\n",
            "[76]. Lynn and Embley developed a semantic enrichment algorithm whose input is canonicalized tables obtained using\n",
            "Jha and Nagy’s Wang Notation Tool. A lexicon and a domain concept-rich library of regular expressions is used for\n",
            "mappings, relationships and constraints discovery [77]. Similarly, Hignette et al. make use of ontology for defining\n",
            "tables. The approach finds cosine similarity between ontology terms and the title and content of the column. It tests table\n",
            "compliance with ontology by relevant matches and fuzzy measure of respective relevance [78]. Table 3 shows that the\n",
            "use of a pre-compiled catalogue for table annotation remains the dominant approach in the literature. Sometimes entity\n",
            "annotation needs semantic enrichment from external knowledge resources [69, 70]. Determining the main concepts asso-\n",
            "ciated with tables can be done using single-entity column values and remaining column headers [84] where concept\n",
            "extraction is done using the Probase knowledge base [113]. However, the approach is limited as it deals with columns\n",
            "not with cells and it only aims at concepts associated with tables. The knowledge base used is not dynamic like that of\n",
            "DBpedia, YAGO or Linked Open Data (LOD) cloud.\n",
            "\n",
            "YAGO [114] can be used for extracting multiple labels for each column in a table and discovering relations between\n",
            "columns [85]. Both concept identification for columns and relation identification are based on maximum likelihood\n",
            "hypotheses similar to the one presented in Limaye et al. [79], that is, the best class label (or relation) is one that maxi-\n",
            "mizes the probability of values given by class label (or relation) for the column. This approach uses YAGO ontology,\n",
            "which is built on top of Wikipedia [115], to label cells with entity IDs, and to label table columns as well as finding bin-\n",
            "ary relationships between columns using probabilistic graphical model-based framework. A single label is chosen from\n",
            "YAGO and the algorithm searches for maximum values of variables, leveraging their joint probability. The dataset used\n",
            "in this approach is the Wiki manual, which is publicly available [79]. The goal is to boost the joint inference about each\n",
            "table based on labels. The approach is limited because of using YAGO for finding relationships as it includes a small\n",
            "fraction of labels and less than 100 binary relationships [116]. Another approach processes web pages for normalizing\n",
            "and interpreting tables for determining attribute–value pair formation [117].\n",
            "\n",
            "Web pages can also be used for table annotation as web pages are richer than YAGO; however, this work is limited\n",
            "to columns and does not deal with cells. Both this approach and the approach presented by Limaye et al. [79] are unable\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "Table 3. Semantics extraction techniques.\n",
            "\n",
            "51\n",
            "\n",
            "Document type\n",
            "\n",
            "HTML\n",
            "\n",
            "PDF\n",
            "\n",
            "Text\n",
            "\n",
            "Image\n",
            "\n",
            "XLS\n",
            "\n",
            "Tool based\n",
            "Ontological based\n",
            "Pre compiled catalogue\n",
            "LOD datasets\n",
            "Web pages\n",
            "RDF triple\n",
            "By surrounding text\n",
            "Unknown entities\n",
            "Snippets\n",
            "Kb enrichment\n",
            "Ontology enrichment\n",
            "Document corpus\n",
            "Word net\n",
            "Multiple domain\n",
            "Data_ Frame Library\n",
            "\n",
            "[76, 77]\n",
            "[40, 62, 72, 78, 82, 106, 107]\n",
            "[18, 83–85, 109]\n",
            "[79, 82, 109]\n",
            "[85]\n",
            "[82, 83]\n",
            "[80, 86]\n",
            "[18, 83]\n",
            "[83]\n",
            "[83]\n",
            "—\n",
            "—\n",
            "[77, 109]\n",
            "—\n",
            "[77]\n",
            "\n",
            "—\n",
            "[41, 60]\n",
            "[81]\n",
            "—\n",
            "—\n",
            "[81, 109]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "[60]\n",
            "\n",
            "[60]\n",
            "[81]\n",
            "—\n",
            "\n",
            "[5, 23, 70, 96]\n",
            "[9]\n",
            "[9, 70]\n",
            "—\n",
            "—\n",
            "—\n",
            "[69, 75]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "[70]\n",
            "[9, 69, 70, 75]\n",
            "—\n",
            "—\n",
            "\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "[71]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "\n",
            "—\n",
            "[107, 108]\n",
            "[88]\n",
            "—\n",
            "—\n",
            "[87, 88]\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "—\n",
            "\n",
            "to annotate new entities not listed in the catalogue. All of the mentioned systems are either manual or semi-automated,\n",
            "working with string values or ignoring literals. To the best of our knowledge there is no tool that truly and completely\n",
            "automates interpretation of a table and thus the output of these systems is raw strings. Therefore no accurate RDF linked\n",
            "data are obtained. Amin et al. [80] proposed an algorithm that labels each column of a table using a Wikipedia best\n",
            "describing category based on column content. This technique does not deal with ambiguous results from Wikipedia and\n",
            "also ignores entities that are unknown to Wikipedia. Another related but rather different approach is the domain-\n",
            "independent interpretation of data in which an automated interpretation of a table is carried out that focuses on column\n",
            "headers, row values and relations between columns. The technique is based on graphical modelling and probabilistic rea-\n",
            "soning, providing results as RDF triples. These also focus on literals and work across multiple domain-web tables, and\n",
            "medical and open government data [81].\n",
            "\n",
            "None of above-mentioned methods and proposed techniques provides domain-independent interpretation of tables.\n",
            "For table annotation Venetis crawls web pages using regular expressions to obtain class information [85]. This web-\n",
            "crawled database has a wider coverage than any modelled ontological database, but suffers from more noise [118]. The\n",
            "above-mentioned approaches present annotated tables using existing knowledge bases [80, 81], ontologies [61, 79] or\n",
            "information that is automatically extracted from web pages [85] and therefore annotate only those entities that are known,\n",
            "whereas annotating missing entities remains untouched Annotating messing entities that do not exist in reference catalo-\n",
            "gue is addressed by some researchers [18, 73, 83]. In these approaches, missing entities annotation is done using text clas-\n",
            "sifiers over snippets returned by search engines [18], using ITEM tool for extracting tables whose structure resembles the\n",
            "RDF knowledge base where new tuples are identified and stored in knowledge base [83] or using ITEM but not using the\n",
            "RDF knowledge base for detecting new entities in tables, Google Fusion Tables (GFT) [73]. The latter approach dis-\n",
            "covers new entities of tables but it is not essential that schema of entities must match the database. The latest and richest\n",
            "open knowledge bases are YAGO [114], DBpedia [115] and Freebase.21 In the literature, tables are annotated by pre-\n",
            "compiled catalogue of entities, types of relationships [18, 81, 85], LOD datasets [79] or ontologies [61]. Probase contains\n",
            "2.7 million concepts and is estimated to include concepts/entities that occur in more than 80% of web searches [86].\n",
            "\n",
            "GFT is a popular web application provided by Google that allows people, including those with no database expertise,\n",
            "to manage their data [18]. Cimiano and Vo¨lker [75] use WordNet for annotation purposes and Fleischman and Hovy\n",
            "[69] use a document corpus for entity annotation. Ontologies can be used for extracting information from tables. One\n",
            "approach is recognizing GFT tables from specific fields using ontology to extract information from tables and filling the\n",
            "ontology with the extracted information [86]. A similar approach is the use of the ITEM tool without using the RDF\n",
            "knowledge base for new entity identification in GFT tables. It identifies new entities by applying a trained text classifier\n",
            "on snippets returned by search engines (Microsoft Bing API). Ambiguous results from snippets about entity description\n",
            "are not handled by this approach [86]. Table information can also be used in enriching knowledge sources. In this regard,\n",
            "one approach can be the use of a catalogue, but entities not present in the catalogue cannot be identified [73]. Tables\n",
            "whose structure matches schema are retrieved and tuples that are not present in the database are added. The aim is to fill\n",
            "an OWL ontology, which is used in data identification and extraction process, and to convert the obtained data into\n",
            "RDF. Normally text surrounding a table is very important for clarifying table semantics if the table itself cannot clarify\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "52\n",
            "\n",
            "all the concepts. Sometimes entities are context-dependent and can be annotated with surrounding text using domain\n",
            "ontology [119]. However, the technique is limited owing to weak programing and limited domain ontology.\n",
            "\n",
            "Table 3 shows that no single approach is perfect for annotating all types of tables in all domains. Selection of the best\n",
            "possible approach in any domain depends on user requirements and available annotation resources. If table annotation\n",
            "using surrounding text is required, then a rule-based approach will give good performance. For annotation of table enti-\n",
            "ties using online knowledge sources, an active learning technique would be best choice as it saves time in the rule-\n",
            "building process. Most methods use knowledge from outside the system; however, the available knowledge sources are\n",
            "not sufficient to cover all domains. Therefore, full context-independent interpretation of tables is not always true. Table 3\n",
            "shows that semantic analysis of PDF tables is quite recent. Finding semantic similarity between tables is a line of oppor-\n",
            "tunity as almost no work has been found in the literature in this direction. Few authors have targeted the interpretation\n",
            "task. Authors either use context-specific interpretation, which works well for specific context but cannot be adopted for\n",
            "tables in general, or they use context-independent interpretation, which makes them unable to gain full fruit of interpreta-\n",
            "tion. Ontological-based approaches are also not able to cover domain independent table interpretation. For domain-\n",
            "specific interpretation they also requires full grasp of domain-specific knowledge for good table annotation. In the table\n",
            "interpretation case a mixed technique should be adopted using text surrounding the table and online knowledge sources\n",
            "with search engine snippets. Also, the integration of several knowledge bases, each containing domain-specific data,\n",
            "might be worthwhile.\n",
            "\n",
            "5. Conclusion and future work\n",
            "\n",
            "The importance of tables in web pages, books and other scholarly documents cannot be ignored while searching them. A\n",
            "huge and rich literature is available highlighting different aspects of table detection, extraction, exploration, classification\n",
            "and annotation. In this paper we highlighted this importance, contributing an evaluation framework for comparing differ-\n",
            "ent information extraction tools and techniques that could be used in processing documents containing tables. The most\n",
            "important aspect is the contribution of the state of the art in table-related research. We came to the conclusion that table\n",
            "identification and extraction tools should be improved in precision and performance because table annotation directly\n",
            "depends on the results of the extraction tools. We highlighted the shortcomings of current rule-based, heuristics-based,\n",
            "wrapper-based and statistical-based techniques for handling tables.\n",
            "\n",
            "By analysing the available table annotation techniques it can be concluded that finding similarities between tables and\n",
            "the measure of their distance, referencing tables in the same or other documents, text/table conversion, ER/table conver-\n",
            "sion, standard datasets and evaluation matrices, making high-performance generalized table annotation algorithms, table\n",
            "recommendation systems, the role of tables in document summarization, classification, and clustering, fully automated\n",
            "ontology generation for table annotation, optimal ranking and table search algorithms are potential research areas in the\n",
            "field. The fact that no significant work has so far been contributed on book table extraction and annotation necessitates\n",
            "the adoption og mechanisms for handling book tables, whether these are present in PDF or other similar formats includ-\n",
            "ing e-pub, DjVu and chm.\n",
            "\n",
            "A number of book-searching solutions and book search engines are available; however, they are not efficient and pre-\n",
            "cise enough to cope with the needs of all book-searching users. Tables being an important component of books and other\n",
            "scholarly documents, their semantics need to be incorporated into the search process so that one can specify a particular\n",
            "table in a book and ask the search engines to find related tables in other books that conceptually summarize, elaborate\n",
            "and compare the concepts and data presented in the selected table. With the incorporation of such semantics, ‘under-\n",
            "standing’ of a particular table will become much easier and readers will not have to manually search for books, which\n",
            "will reduce the resulting cognitive load. Also the need here is the implementation of a true book search engine that can\n",
            "find, annotate and rank book tables so that similar books can be searched on certain parameters. A combined approach\n",
            "should be applied for book table annotation using online knowledge sources and semantic analysers. The entities of book\n",
            "tables which are missing should be annotated using search engine results and by extracting paragraphs surrounding\n",
            "tables. There is a serious need for PDF table extraction and annotation tools that could extract tables from PDF docu-\n",
            "ments with higher accuracy and annotate them using concepts from the surrounding text, other points of reference and\n",
            "external sources.\n",
            "\n",
            "Funding\n",
            "\n",
            "This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "53\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "Notes\n",
            "\n",
            "1. http://www.greenstone.org\n",
            "2. http://pdfbox.apache.org\n",
            "3. http://itextpdf.com\n",
            "4. http://www.icepdf.org\n",
            "5. https://github.com/ashima/pdf-table-extract\n",
            "6. http://tabula.nerdpower.org\n",
            "7. http://www.snapfiles.com/get/pdf2html.html\n",
            "8. http://www.verypdf.com/app/pdf-table-extractor\n",
            "9. http://www.adobe.com/products/catalog/services.html\n",
            "\n",
            "10. http://ieg.ifs.tuwien.ac.at/projects/pdf2table\n",
            "11. http://www.soliddocuments.com\n",
            "12. http://www.pdf-tools.com\n",
            "13. http://www.pdflib.com/products/tet\n",
            "14. http://pdftransformer.abbyy.com\n",
            "15. http://okular.kde.org\n",
            "16. http://finereader.abbyy.com/corporate/\n",
            "17. http://www.adobe.com/products/acrobatpro/features.html\n",
            "18. http://www.nuance.com/for-business/by-product/omnipage/ultimate/index.htm\n",
            "19. http://www.nitropdf.com/\n",
            "20. http://www.visionbib.com/bibliography/char969.html\n",
            "21. http://www.freebase.com\n",
            "\n",
            "References\n",
            "\n",
            "[1] Yıldız B. Information extraction–utilizing table patterns: Master’s thesis, Vienna University of Technology, 2004.\n",
            "[2] Bienz T, Cohn R and Meehan J. Portable document format reference manual. Addison-Wesley Reading, MA, USA, 1993.\n",
            "[3] Merz T. Web Publishing with Acrobat/PDF. Berlin: Springer, 1998.\n",
            "[4] Pitfalls CFPTXMWAT. White paper, 2003.\n",
            "[5] Hurst M. Towards a theory of tables. International Journal of Document Analysis and Recognition (IJDAR) 2006; 8(2–3): 123–\n",
            "\n",
            "131.\n",
            "\n",
            "[6] Long V, Dale R and Cassidy S (eds). A model for detecting and merging vertically spanned table cells in plain text documents.\n",
            "\n",
            "In: Proceedings eighth international conference on document analysis and recognition. New York: IEEE, 2005.\n",
            "\n",
            "[7] Peterman C, Chang CH and Alam H (eds). A system for table understanding. In: Proceedings of the symposium on document\n",
            "\n",
            "image understanding technology (SDIUT’97), 1997.\n",
            "\n",
            "[8] Cameron JP. A cognitive model for tabular editing. Ohio State University, Computer & Information Science Research Center,\n",
            "\n",
            "1989.\n",
            "\n",
            "[9] Silva AC, Jorge AM and Torgo L. Design of an end-to-end method to extract information from tables. International Journal of\n",
            "\n",
            "Document Analysis and Recognition (IJDAR) 2006; 8(2–3): 144–171.\n",
            "\n",
            "[10] Lopresti D and Nagy G. A tabular survey of automated table processing. In: Graphics recognition recent advances. Berlin:\n",
            "\n",
            "Springer, 2000, pp. 93–120.\n",
            "\n",
            "[11] Wong W, Martinez D and Cavedon L (eds). Extraction of named entities from tables in gene mutation literature. In:\n",
            "Proceedings of the workshop on current trends in biomedical natural language processing. Association for Computational\n",
            "Linguistics, 2009.\n",
            "\n",
            "[12] Fang J, Tao X, Tang Z, Qiu R and Liu Y (eds). Dataset, ground-truth and performance metrics for table detection evaluation. In:\n",
            "\n",
            "10th IAPR international workshop on document analysis systems (DAS). New York: IEEE, 2012.\n",
            "\n",
            "[13] Long V. An agent-based approach to table recognition and interpretation. Macquarie University Sydney, Australia, 2010.\n",
            "[14] Wang Y, Phillips IT and Haralick RM. Table structure understanding and its performance evaluation. Pattern Recognition\n",
            "\n",
            "2004; 37(7): 1479–1497.\n",
            "\n",
            "[15] Lewandowsky S and Spence I. The perception of statistical graphs. Sociological Methods & Research 1989; 18(2–3): 200–242.\n",
            "[16] Vanoirbeek C (ed.). Formatting structured tables. In: EP92, Proceedings of electronic publishing, 1992.\n",
            "[17] Liu Y. Tableseer: Automatic table extraction, search, and understanding. The Pennsylvania State University, 2009.\n",
            "[18] Quercini G and Reynaud C (eds). Entity discovery and annotation in tables. In: Proceedings of the 16th international conference\n",
            "\n",
            "on extending database technology. New York: ACM, 2013.\n",
            "\n",
            "[19] Schmoekel I. PDF-analyzer pro 4.0. Software-development and distribution. AchimUesen, Germany, 2010, Vol. 1, pp. 1–11.\n",
            "[20] Amyuni T. PDF Vol. 2010. Montreal: Amyuni Technologies, 2010.\n",
            "[21] Liu Y, Bai K, Mitra P and Giles CL (eds). Tableseer: Automatic table metadata extraction and searching in digital libraries. In:\n",
            "\n",
            "Proceedings of the 7th ACM/IEEE-CS joint conference on digital libraries. New York: ACM, 2007.\n",
            "\n",
            "[22] Friedman DKaN. Probabilistic graphical models: Principles and techniques. Cambridge, MA: MIT Press, 2009.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "54\n",
            "\n",
            "[23] Kornfeld W and Wattecamps J (eds). Automatically locating, extracting and analyzing tabular data. In: Proceedings of the 21st\n",
            "\n",
            "annual international ACM SIGIR conference on research and development in information retrieval. New York: ACM, 1998.\n",
            "\n",
            "[24] Embley DW, Lopresti D and Nagy G. Table-processing paradigms: A research survey. International Journal on Document\n",
            "\n",
            "Analysis and Recognition 2006; 8(2): 66–86.\n",
            "\n",
            "[25] Fang J, Gao L, Bai K, Qiu R, Tao X and Tang Z (eds). A table detection method for multipage pdf documents via visual sepera-\n",
            "tors and tabular structures. In: International conference on document analysis and recognition (ICDAR). New York: IEEE,\n",
            "2011.\n",
            "\n",
            "[26] Zanibbi R, Blostein D and Cordy JR. A survey of table recognition. Document Analysis and Recognition 2004; 7(1): 1–16.\n",
            "[27] Pyreddy P and Croft WB (eds). Tintin: A system for retrieval in text tables. In: Proceedings of the second ACM international\n",
            "\n",
            "conference on digital libraries. New York: ACM, 1997.\n",
            "\n",
            "[28] Rus D and Summers K. Using white space for automated document structuring. Ithaca, NY: Cornell University, 1994.\n",
            "[29] Klein B, Gokkus S, Kieninger T and Dengel A (eds). Three approaches to ‘industrial’ table spotting. In: Proceedings of the sixth\n",
            "\n",
            "international conference on document analysis and recognition. New York: IEEE, 2001.\n",
            "\n",
            "[30] Hu J, Kashi RS, Lopresti DP and Wilfong G (eds). Medium-independent table detection. Electronic Imaging. International\n",
            "\n",
            "Society for Optics and Photonics, 1999.\n",
            "\n",
            "[31] Ng HT, Lim CY and Koo JLT (eds). Learning to recognize tables in free text. In: Proceedings of the 37th annual meeting of the\n",
            "\n",
            "Association for Computational Linguistics on Computational Linguistics. Association for Computational Linguistics, 1999.\n",
            "\n",
            "[32] Kieninger TG (ed.). Table structure recognition based on robust block segmentation. In: Photonics west’98: Electronic imaging.\n",
            "\n",
            "International Society for Optics and Photonics, 1998.\n",
            "\n",
            "[33] Pinto D, Branstein M, Coleman R, Croft WB, King M, Li W et al. (eds). QuASM: a system for question answering using semi-\n",
            "\n",
            "structured data. In: Proceedings of the 2nd ACM/IEEE-CS joint conference on Digital libraries. New York: ACM, 2002.\n",
            "\n",
            "[34] Pinto D, McCallum A, Wei X and Croft WB (eds). Table extraction using conditional random fields. In: Proceedings of the\n",
            "26th annual international ACM SIGIR conference on Research and development in informaion retrieval. New York: ACM,\n",
            "2003.\n",
            "\n",
            "[35] Green EA and Krishnamoorthy MS. Model-based analysis of printed tables. In: Graphics Recognition Methods and\n",
            "\n",
            "Applications. Berlin: Springer, 1996, pp. 80–91.\n",
            "\n",
            "[36] Tupaj S, Shi Z, Chang CH and Alam H. Extracting tabular information from text files. EECS Department, Tufts University,\n",
            "\n",
            "Medford, USA. 1996.\n",
            "\n",
            "[37] Shamilian JH, Baird HS and Wood TL (eds). A retargetable table reader. In: Proceedings of the fourth international conference\n",
            "\n",
            "on document analysis and recognition. New York: IEEE, 1997.\n",
            "\n",
            "[38] Kieninger T and Dengel A (eds). A paper-to-HTML table converting system. In: Proceedings of document analysis systems\n",
            "\n",
            "(DAS), 1998.\n",
            "\n",
            "[39] Cesarini F, Marinai S, Sarti L and Soda G (eds). Trainable table location in document images. In: Proceedings 16th interna-\n",
            "\n",
            "tional conference on pattern recognition. New York: IEEE, 2002.\n",
            "\n",
            "[40] Wang Y and Hu J. Detecting tables in html documents. In: Document analysis systems V. Berlin: Springer, 2002, pp. 249–260.\n",
            "[41] Ferguson D (ed.). Parsing financial statements efficiently and accurately using C and Prolog. In: Proceedings of the fifth interna-\n",
            "\n",
            "tional conference on the practical application of Prolog, London, 1997.\n",
            "\n",
            "[42] Ramel J-Y, Crucianu M, Vincent N and Faure C (eds). Detection, extraction and representation of tables. In: proceedings\n",
            "\n",
            "seventh international conference on document analysis and recognition. New York: IEEE, 2003.\n",
            "\n",
            "[43] Chen H-H, Tsai S-C and Tsai J-H (eds). Mining tables from large scale HTML texts. In: Proceedings of the 18th conference on\n",
            "\n",
            "Computational linguistics, Volume 1. Association for Computational Linguistics, 2000.\n",
            "\n",
            "[44] Cohen WW, Hurst M and Jensen LS (eds). A flexible learning system for wrapping tables and lists in HTML documents. In:\n",
            "\n",
            "Proceedings of the 11th international conference on World Wide Web. New York: ACM, 2002.\n",
            "\n",
            "[45] Wang Y and Hu J (eds). A machine learning based approach for table detection on the web. In: Proceedings of the 11th interna-\n",
            "\n",
            "tional conference on World Wide Web. New York: ACM, 2002.\n",
            "\n",
            "[46] Zhang X-w, Lyu MR and Dai G-z. Extraction and segmentation of tables from Chinese ink documents based on a matrix model.\n",
            "\n",
            "Pattern Recognition 2007; 40(7): 1855–1867.\n",
            "\n",
            "[47] Nagy G and Tamhankar M. VeriClick: An efficient tool for table format verification. In: IS&T/SPIE electronic imaging.\n",
            "\n",
            "International Society for Optics and Photonics, 2012, p. 82970M.\n",
            "\n",
            "[48] Yildiz B, Kaiser K and Miksch S (eds). pdf2table: A method to extract table information from PDF files. IICAI, 2005.\n",
            "[49]\n",
            "\n",
            "Jiang D and Yang X (eds). Converting PDF to HTML approach based on text detection. In: Proceedings of the 2nd international\n",
            "conference on interaction sciences: information technology, culture and human. New York: ACM, 2009.\n",
            "\n",
            "[50] Mohemad R, Hamdan AR, Othman ZA and Noor NM. Automatic document structure analysis of structured PDF files.\n",
            "\n",
            "International Journal of New Computer Architectures and their Applications (IJNCAA), 2011, Vol. 1(2): 404–411.\n",
            "\n",
            "[51] Liu Y, Bai K, Mitra P and Giles CL (eds). Tablerank: A ranking algorithm for table search and retrieval. In: Proceedings of the\n",
            "\n",
            "national conference on artificial intelligence, Menlo Park, CA/Cambridge, MA: AAAI Press/MIT Press, 2007.\n",
            "\n",
            "[52] Hurst M (ed.). Layout and language: An efficient algorithm for detecting text blocks based on spatial and linguistic evidence.\n",
            "\n",
            "In: Photonics west 2001 – Electronic imaging. International Society for Optics and Photonics, 2000.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "55\n",
            "\n",
            "[53] Douglas S, Hurst M and Quinn D (eds). Using natural language processing for identifying and interpreting tables in plain text.\n",
            "\n",
            "In: Proceedings of the fourth annual symposium on document analysis and information retrieval. Citeseer, 1995.\n",
            "\n",
            "[54] Shin J and Guerette N (eds). Table recognition and evaluation. In: Class of 2005 senior conference on natural language process-\n",
            "\n",
            "ing. Citeseer, 2005.\n",
            "\n",
            "[55] Mandal S, Chowdhury S, Das AK and Chanda B. A simple and effective table detection system from document images.\n",
            "\n",
            "International Journal of Document Analysis and Recognition (IJDAR) 2006; 8(2–3): 172–182.\n",
            "\n",
            "[56] Liu Y, Mitra P, Giles CL and Bai K (eds). Automatic extraction of table metadata from digital documents. In: Proceedings of\n",
            "\n",
            "the 6th ACM/IEEE-CS joint conference on digital libraries. New York: ACM, 2006.\n",
            "\n",
            "[57] Li J, Tang J, Song Q and Xu P. Table detection from plain text using machine learning and document structure. In: Frontiers of\n",
            "\n",
            "WWW research and development – APWeb 2006. Berlin: Springer, 2006, pp. 818–823.\n",
            "\n",
            "[58] Hassan T and Baumgartner R (eds). Table recognition and understanding from pdf files. In: Ninth international conference on\n",
            "\n",
            "document analysis and recognition, ICDAR 2007. New York: IEEE, 2007.\n",
            "\n",
            "[59] Liu Y, Mitra P and Giles CL (eds). Identifying table boundaries in digital documents via sparse line detection. In: Proceedings\n",
            "\n",
            "of the 17th ACM conference on information and knowledge management. New York: ACM, 2008.\n",
            "\n",
            "[60] Oro E and Ruffolo M (eds). Pdf-trex: An approach for recognizing and extracting tables from pdf documents. In: ICDAR’09:\n",
            "\n",
            "10th international conference on document analysis and recognition. New York: IEEE, 2009.\n",
            "\n",
            "[61] Oro E and Ruffolo M (eds). Xonto: An ontology-based system for semantic information extraction from pdf documents. In:\n",
            "\n",
            "ICTAI’08: 20th IEEE international conference on tools with artificial intelligence. New York: IEEE, 2008.\n",
            "\n",
            "[62] Embley DW, Tao C and Liddle SW. Automating the extraction of data from HTML tables with unknown structure. Data &\n",
            "\n",
            "Knowledge Engineering 2005; 54(1): 3–28.\n",
            "\n",
            "[63] Gatterbauer W, Bohunsky P, Herzog M, Kru¨pl B and Pollak B (eds). Towards domain-independent information extraction from\n",
            "\n",
            "web tables. In: Proceedings of the 16th international conference on World Wide Web. New York: ACM, 2007.\n",
            "\n",
            "[64] Silva AC (ed.). Learning rich hidden Markov models in document analysis: Table location. In: ICDAR, 2009.\n",
            "[65] Lafferty J, McCallum A and Pereira FC. Conditional random fields: Probabilistic models for segmenting and labeling sequence\n",
            "\n",
            "data, 2001.\n",
            "\n",
            "[66] Hurst M (ed.). Layout and language: Challenges for table understanding on the web. In: Proceedings of the international work-\n",
            "\n",
            "shop on Web document analysis. Citeseer, 2001.\n",
            "\n",
            "[67] Wei X, Croft B and McCallum A. Table extraction for answer retrieval. Information Retrieval 2006; 9(5): 589–611.\n",
            "[68] Silva AC (ed.). New metrics for evaluating performance in document analysis tasks – application to the table case. In: ICDAR,\n",
            "\n",
            "2007.\n",
            "\n",
            "[69] Fleischman M and Hovy E (eds). Fine grained classification of named entities. In: Proceedings of the 19th international confer-\n",
            "\n",
            "ence on Computational linguistics – Vol. 1. Association for Computational Linguistics, 2002.\n",
            "\n",
            "[70] Ganti V, Ko¨nig AC and Vernica R (eds). Entity categorization over large document collections. In: Proceedings of the 14th\n",
            "\n",
            "ACM SIGKDD international conference on knowledge discovery and data mining. New York: ACM, 2008.\n",
            "\n",
            "[71] Wang X and Wood D. Tabular abstraction, editing, and formatting. Citeseer, 1996.\n",
            "[72] Tijerino YA, Embley DW, Lonsdale DW, Ding Y and Nagy G. Towards ontology generation from tables. World Wide Web\n",
            "\n",
            "2005; 8(3): 261–285.\n",
            "\n",
            "[73] Shahab A, Shafait F, Kieninger T and Dengel A (eds). An open approach towards the benchmarking of table structure recogni-\n",
            "\n",
            "tion systems. In: Proceedings of the 9th IAPR international workshop on document analysis systems. New York: ACM, 2010.\n",
            "\n",
            "[74] Go¨bel M, Hassan T, Oro E and Orsi G (eds). A methodology for evaluating algorithms for table understanding in PDF docu-\n",
            "\n",
            "ments. In: Proceedings of the 2012 ACM symposium on document engineering. New York: ACM, 2012.\n",
            "\n",
            "[75] Cimiano P and Vo¨lker J (eds). Towards large-scale, open-domain and ontology-based named entity classification. In:\n",
            "\n",
            "Proceedings of the international conference on recent advances in natural language processing (RANLP), 2005.\n",
            "Jha P. Wang notation tool: A layout independent representation of tables. Rensselaer Polytechnic Institute, 2008.\n",
            "\n",
            "[76]\n",
            "[77] Lynn S and Embley DW. Semantically conceptualizing and annotating tables. In: The Semantic Web. Berlin: Springer, 2008,\n",
            "\n",
            "pp. 345–359.\n",
            "\n",
            "[78] Hignette G, Buche P, Dibie-Barthe´lemy J and Haemmerle´ O. Fuzzy annotation of web data tables driven by a domain ontology.\n",
            "\n",
            "In: The Semantic Web: Research and applications. Berlin: Springer, 2009, pp. 638–653.\n",
            "\n",
            "[79] Limaye G, Sarawagi S and Chakrabarti S. Annotating and searching web tables using entities, types and relationships. In:\n",
            "\n",
            "Proceedings of the VLDB endowment, 2010; Vol. 3(1–2), pp. 1338–1347.\n",
            "\n",
            "[80] Amin MS, Bhattacharjee A and Jamil H (eds). Wikipedia driven autonomous label assignment in wrapper induced tables with\n",
            "\n",
            "missing column names. In: Proceedings of the 2010 ACM symposium on applied computing. New York: ACM, 2010.\n",
            "\n",
            "[81] Mulwad V, Finin T and Joshi A (eds). Generating linked data by inferring the semantics of tables. In: VLDS, 2011.\n",
            "[82] Mulwad V. T2LD – An automatic framework for extracting, interpreting and representing tables as Linked Data. University of\n",
            "\n",
            "Maryland, 2010.\n",
            "\n",
            "[83] Guo X, Chen Y, Chen J and Du X. ITEM: Extract and integrate entities from tabular data to RDF knowledge base. In:\n",
            "APWeb’11: Proceedings of the 13th Asia-Pacific Web conference on Web technologies and applications. Berlin: Springer,\n",
            "2011, pp. 400–411.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "56\n",
            "\n",
            "[84] Wang J, Wang H, Wang Z and Zhu KQ. Understanding tables on the web. In: Conceptual modeling. Berlin: Springer, 2012, pp.\n",
            "\n",
            "141–155.\n",
            "\n",
            "[85] Venetis P, Halevy A, Madhavan J, Pasxca M, Shen W, Wu F et al. Recovering semantics of tables on the web. In: Proceedings\n",
            "\n",
            "of the VLDB endowment, 2011; Vol. 4(9), pp. 528–538.\n",
            "\n",
            "[86] Quercini G and Reynaud C (eds). Des donne´es tabulaires a` RDF: l’extraction de donne´es de Google Fusion Tables. In: Atelier\n",
            "\n",
            "Ontologies et Jeux de Donne´es pour e´valuer le Web Se´mantique (OJD) associe´ a` IC’2012, 2012.\n",
            "\n",
            "[87] Han L, Finin T, Parr C, Sachs J and Joshi A. RDF123: From spreadsheets to RDF. In: The Semantic Web – ISWC. Berlin:\n",
            "\n",
            "Springer, 2008, pp. 451–466.\n",
            "\n",
            "[88] Van Assem M, Rijgersberg H, Wigham M and Top J. Converting and annotating quantitative data tables. In: The Semantic Web\n",
            "\n",
            "– ISWC. Berlin: Springer, 2010, pp. 16–31.\n",
            "\n",
            "[89] Kieninger T and Dengel A (eds). Applying the T-RECS table recognition system to the business letter domain. In: Proceedings\n",
            "\n",
            "sixth international conference on document analysis and recognition. New York: IEEE, 2001.\n",
            "\n",
            "[90] Pereira FSaF. Shallow parsing with conditional random fields, 2003.\n",
            "[91] McCallum A and Li W (eds). Early results for named entity recognition with conditional random fields, feature induction and\n",
            "web-enhanced lexicons. In: Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003, Vol. 4.\n",
            "Association for Computational Linguistics, 2003.\n",
            "\n",
            "[92] Gao L, Tang Z, Lin X, Liu Y, Qiu R and Wang Y (eds). Structure extraction from PDF-based book documents. In: Proceedings\n",
            "\n",
            "of the 11th annual international ACM/IEEE joint conference on digital libraries. New York: ACM, 2011.\n",
            "\n",
            "[93] Embley DW, Lopresti D and Nagy G. Notes on contemporary table recognition. In: Document analysis systems VII. Berlin:\n",
            "\n",
            "Springer, 2006, pp. 164–175.\n",
            "\n",
            "[94] Amano A and Asada N (eds). Graph grammar based analysis system of complex table form document. In: ICDAR. Citeseer,\n",
            "\n",
            "2003.\n",
            "\n",
            "[95] Wang Y, Phillips IT and Haralick R (eds). Automatic table ground truth generation and a background-analysis-based table struc-\n",
            "ture extraction method. In: Proceedings sixth international conference on document analysis and recognition. New York: IEEE,\n",
            "2001.\n",
            "\n",
            "[96] Hurst MF. The interpretation of tables in texts, 2000.\n",
            "[97] Wang C, Xie X, Wang W and Ma W-Y. Improving web browsing on small devices based on table classification. In: Advances\n",
            "\n",
            "in multimedia information processing – PCM 2004. Berlin: Springer, 2005, pp. 88–95.\n",
            "\n",
            "[98] Pivk A, Cimiano P and Sure Y. From tables to frames. Berlin: Springer, 2004.\n",
            "[99] Yoshida M, Torisawa K and Tsujii J. A method to integrate tables of the world wide web. In: Proceedings of the international\n",
            "\n",
            "workshop on Web document analysis. WDA, 2001, pp. 31–34.\n",
            "\n",
            "[100] Tenopir C, Sandusky RJ and Casado MM. Uses of figures and tables from scholarly journal articles in teaching and research,\n",
            "\n",
            "2007.\n",
            "\n",
            "[101] Hearst MA, Divoli A, Guturu H, Ksikes A, Nakov P, Wooldridge MA et al. BioText Search Engine: Beyond abstract search.\n",
            "\n",
            "Bioinformatics 2007; 23(16): 2196–2197.\n",
            "\n",
            "[102] Mitra CBASaM. Pivoted document length normalization. In: Proceedings of the 19th annual international ACM SIGIR confer-\n",
            "\n",
            "ence on research and development in information retrieval. New York: ACM, p. 21C9.\n",
            "\n",
            "[103] Ponte JM and Croft WB. A language modeling approach to information retrieval. In: Proceedings of 21st annual international\n",
            "ACM SIGIR conference on research and development in information retrieval, Melbourne. New York: ACM, 1998, pp. 275–\n",
            "281.\n",
            "\n",
            "[104] Robertson WE, Walker S and Beaulieu M. Okapi at trecc7: Automatic ad hoc, filtering, vlc and filtering tracks. In: 7th text\n",
            "\n",
            "retrieval conference, TREC7. NIST Special Publications, SP 500-242,1998, p. 253.\n",
            "\n",
            "[105] Brin LPS. The anatomy of a large-scale hypertextual web search engine. In: Proceedings of the seventh international confer-\n",
            "\n",
            "ence on World Wide Web, 1999, pp. 107–117.\n",
            "\n",
            "[106] Varish M (ed.). DC proposal: Graphical models and probabilistic reasoning for generating linked data from tables. In:\n",
            "\n",
            "Proceedings of tenth international Semantic Web conference, Part II, 2011.\n",
            "\n",
            "[107] Ramana C, Jandhyala MK, Nagy G, Padmanabhan R, Seth S and Silversmith W. From tessellations to table interpretation.\n",
            "\n",
            "Berlin: Springer, 2009.\n",
            "\n",
            "[108] Nagy G, Padmanabhan R, Jandhyala RC and Silversmith W. Table metadata: Headers, augmentations and aggregates.\n",
            "\n",
            "DocLab, Rensselaer Polytechnic Institute, Troy, NY, 2010.\n",
            "\n",
            "[109] Tim Finin ZS, Mulwad V and Joshi A. Exploiting a Web of semantic data for interpreting tables. In: Web science conference,\n",
            "\n",
            "2010.\n",
            "\n",
            "[110] Hu J, Kashi RS, Lopresti D and Wilfong GT. Evaluating the performance of table processing algorithms. International\n",
            "\n",
            "Journal on Document Analysis and Recognition 2002; 4(3): 140–153.\n",
            "\n",
            "[111] Phillips I. User’s reference manual for the UW english/technical document image database III. UW-III English/Technical\n",
            "\n",
            "Document Image Database Manual, 1996.\n",
            "\n",
            "[112] Wang Y, Haralick M, Haralick RM and Phillips IT. Document analysis: Table structure understanding and zone content classi-\n",
            "\n",
            "fication, 2002.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n",
            "Khusro et al.\n",
            "\n",
            "57\n",
            "\n",
            "[113] Wu W, Li H, Wang H and Zhu K. Towards a probabilistic taxonomy of many concepts. Technical Report MSR-TR-2011-25,\n",
            "\n",
            "Microsoft Research, 2011.\n",
            "\n",
            "[114] Suchanek FM, Kasneci G and Weikum G (eds). Yago: A core of semantic knowledge. In: Proceedings of the 16th interna-\n",
            "\n",
            "tional conference on World Wide Web. New York: ACM, 2007.\n",
            "\n",
            "[115] Bizer C, Lehmann J, Kobilarov G, Auer S, Becker C, Cyganiak R et al. DBpedia – A crystallization point for the Web of Data.\n",
            "\n",
            "Web Semantics: Science, Services and Agents on the World Wide Web 2009; 7(3): 154–165.\n",
            "\n",
            "[116] Pitale S and Sharma T. Information Extraction tools for portable document format. International Journal of Computer\n",
            "\n",
            "Technology and Applications 2011; 2(6).\n",
            "\n",
            "[117] Shaker M, Ibrahim H, Mustapha A and Abdullah N. Information extraction from web tables. In: Proceedings of the 11th inter-\n",
            "\n",
            "national conference on information integration and Web-based applications & services, 2009, pp. 470–476.\n",
            "\n",
            "[118] Zwicklbauer S, Einsiedler C, Granitzer M and Seifert C. Towards disambiguating Web tables. ISWC (P&D) 2013; 205–208.\n",
            "[119] Alrashed SA. Finding hidden semantics of text tables. In: Document analysis systems VII. Berlin: Springer, 2006, pp. 449–461.\n",
            "[120] Beel J, Gipp B, Shaker A, and Friedrich N. SciPlore Xtract: Extracting Titles from Scientific PDF Documents by Analyzing\n",
            "Style Information (Font Size). Research and Advanced Technology for Digital Libraries, LNCS 6273 (Springer, Berlin,\n",
            "2010), 413–416.\n",
            "\n",
            "Journal of Information Science, 41(1) 2015, pp. 41–57 Ó The Author(s), DOI: 10.1177/0165551514551903\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}